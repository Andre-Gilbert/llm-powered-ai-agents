{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM-powered AI Agents\n",
    "\n",
    "Table of contents\n",
    "1. Understanding LLMs\n",
    "2. Tools\n",
    "3. Chat-based AI Agents\n",
    "4. Service-based AI agents\n",
    "5. Multi-Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import uvicorn\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Any\n",
    "from fastapi import FastAPI\n",
    "from io import StringIO\n",
    "from language_models.agents.chain import AgentChain\n",
    "from language_models.models.llm import OpenAILanguageModel, ChatMessage, ChatMessageRole\n",
    "from language_models.tools.tool import Tool\n",
    "from language_models.proxy_client import BTPProxyClient\n",
    "from language_models.agents.react import ReActAgent\n",
    "from language_models.tools.earthquake import earthquake_tools\n",
    "from language_models.tools.current_date import current_date_tool\n",
    "from language_models.settings import settings\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = BTPProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-35-turbo\",\n",
    "    max_tokens=256,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Take the following movie review and determine the sentiment of the review.\n",
    "\n",
    "Movie review:\n",
    "Wow! This movie was incredible. The acting was superb, and\n",
    "the plot kept me on the edge of my seat. I highly recommend it!\"\"\"\n",
    "\n",
    "response = llm.get_completion([ChatMessage(role=ChatMessageRole.USER, content=prompt)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Take the following movie review and determine the sentiment of the review.\n",
    "\n",
    "Movie review:\n",
    "Wow! This movie was incredible. The acting was superb, and\n",
    "the plot kept me on the edge of my seat. I highly recommend it!\n",
    "\n",
    "Respond with positive or negative.\"\"\"\n",
    "\n",
    "response = llm.get_completion([ChatMessage(role=ChatMessageRole.USER, content=prompt)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Take the following movie review and determine the sentiment of the review. Respond with 1 (positive) or 0 (negative).\"\n",
    "\n",
    "prompt = \"Wow! This movie was incredible. The acting was superb, and the plot kept me on the edge of my seat. I highly recommend it!\"\n",
    "\n",
    "response = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Take the following movie review determine the sentiment of the review. Respond with 1 (positive) or 0 (negative).\"\n",
    "\n",
    "prompt = \"Will it rain in Seattle today?\"\n",
    "\n",
    "response = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Take the following movie review and determine the sentiment of the review.\n",
    "\n",
    "Respond with 1 (positive) or 0 (negative).\n",
    "\n",
    "If you don't receive a movie review, respond with -1.\"\"\"\n",
    "\n",
    "prompt = \"Will it rain in Seattle today?\"\n",
    "\n",
    "response = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Total Raw Cost = $549.72 + $6.98 + $41.00 + $35.00 + $552.00 + $76.16 + $29.12\" # answer: $1,289.98\n",
    "\n",
    "response = llm.get_completion([ChatMessage(role=ChatMessageRole.USER, content=prompt)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculator(expression: str) -> Any:\n",
    "    return eval(expression)\n",
    "\n",
    "class Calculator(BaseModel):\n",
    "    expression: str = Field(description=\"A math expression.\")\n",
    "\n",
    "calculator_tool = Tool(\n",
    "    func=calculator,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Use this tool when you want to do calculations.\",\n",
    "    args_schema=Calculator\n",
    ")\n",
    "\n",
    "print(calculator_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"Take the following prompt and calculate the result.\n",
    "\n",
    "Respond to the user as helpfully and accurately as possible.\n",
    "\n",
    "You have access to the following tools: {calculator_tool}\n",
    "\n",
    "Valid \"tool\" values: {calculator_tool.name}\n",
    "\n",
    "Always use the following JSON format:\n",
    "{{\n",
    "  \"thought\": \"You should always think about what to do consider previous and subsequent steps\",\n",
    "  \"tool\": \"The tool to use\",\n",
    "  \"tool_input\": \"Valid key value pairs\",\n",
    "}}\"\"\"\n",
    "\n",
    "prompt = \"Total Raw Cost = $549.72 + $6.98 + $41.00 + $35.00 + $552.00 + $76.16 + $29.12\"\n",
    "\n",
    "response = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "response = json.loads(response, strict=False)\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(calculator(**response[\"tool_input\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"Take the following prompt and calculate the result.\n",
    "\n",
    "Respond to the user as helpfully and accurately as possible.\n",
    "\n",
    "You have access to the following tools: {calculator_tool}\n",
    "\n",
    "Valid \"tool\" values: {calculator_tool.name}\n",
    "\n",
    "Always use the following JSON format:\n",
    "{{\n",
    "  \"thought\": \"You should always think about what to do consider previous and subsequent steps\",\n",
    "  \"tool\": \"The tool to use\",\n",
    "  \"tool_input\": \"Valid key value pairs\",\n",
    "}}\n",
    "\n",
    "Observation: tool result\n",
    "... (this Thought/Tool/Observation can repeat N times)\n",
    "\n",
    "When you know the answer, use the following JSON format:\n",
    "{{\n",
    "  \"thought\": \"I now know what to respond\",\n",
    "  \"tool\": \"Final Answer\",\n",
    "  \"tool_input\": \"The final answer to the question\",\n",
    "}}\"\"\"\n",
    "\n",
    "prompt = \"Total Raw Cost = $549.72 + $6.98 + $41.00 + $35.00 + $552.00 + $76.16 + $29.12\"\n",
    "\n",
    "response = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "    ChatMessage(role=ChatMessageRole.ASSISTANT, content=json.dumps(response)),\n",
    "    ChatMessage(role=ChatMessageRole.ASSISTANT, content=f\"Response of Calculator tool: {calculator(**response['tool_input'])}\"),\n",
    "])\n",
    "response = json.loads(response, strict=False)\n",
    "print(json.dumps(response, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chat-based AI Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Earthquake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an United States Geological Survey expert who can answer questions regarding earthquakes and can run forecasts.\n",
    "\n",
    "Use the current date tool to access the local date and time before using other tools.\n",
    "\n",
    "Take the following question and answer it as accurately as possible.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4-32k',\n",
    "    max_tokens=2048,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"The final answer.\")\n",
    "\n",
    "earthquake_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{question}\",\n",
    "    task_prompt_variables=[\"question\"],\n",
    "    tools=earthquake_tools + [current_date_tool],\n",
    "    output_format=Output,\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = earthquake_agent.invoke({\"question\": \"How many earthquakes have occurred for the past week with a magnitude of 5 or greater?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = earthquake_agent.invoke({\"question\": \"Query 10 earthquakes that occurred yesterday and have a magnitude > 3.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = earthquake_agent.invoke({\"question\": \"Can MegaQuakes really happen? Like a magnitude 10 or larger?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Service-based AI Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contract Drafting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Take the follow content and generate a draft of a section for a contract.\n",
    "\n",
    "Write the content from scratch and make it sound professional.\n",
    "\n",
    "Respond with the title of the section and the content of the section.\"\"\"\n",
    "\n",
    "task_prompt = \"\"\"Section content:\n",
    "{section}\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=1024,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class ContractSection(BaseModel):\n",
    "    title: str = Field(description=\"The title of the section.\")\n",
    "    content: str = Field(description=\"The content of the section.\")\n",
    "\n",
    "contract_drafting_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=task_prompt,\n",
    "    task_prompt_variables=[\"section\", \"section_name\"],\n",
    "    tools=None,\n",
    "    output_format=ContractSection,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_contract(contract_sections: list[str]) -> str:\n",
    "    sections = []\n",
    "    for contract_section in contract_sections:\n",
    "        response = contract_drafting_agent.invoke({\"section\": contract_section})\n",
    "        section = response.final_answer[\"title\"] + \"\\n\\n\" + response.final_answer[\"content\"]\n",
    "        sections.append(section)\n",
    "    return \"\\n\\n\".join(sections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = \"Capitalised terms, singular or plural, used in this Amendment, shall have the same meaning in the GMA.\"\n",
    "\n",
    "amendment = \"\"\"INVOICING AND PAYMENT TERMS\n",
    "Clause 12.1(ii) of the GMA shall be cancelled and substituted as follow:\n",
    "[*****]\n",
    "[*****]\n",
    "[*****]\n",
    "\n",
    "Any other provision of Clause 12 shall remain in full force and effect.\n",
    "\n",
    "PRICE CONDITIONS\n",
    "(i) Clause 3.2 of the Exhibit 14 of the GMA shall be cancelled and substituted as follow:\n",
    "“3.2 Technical conditions for prices adjustment\n",
    "The prices set out in this Exhibit 14 shall be modified every [*****] at the occasion of the invoicing reconciliation pursuant to Clause 11\n",
    "(“Reconciliation”) if the Standard Operations of the Aircraft, analyzed at the time of the adjustment (all calculations are made with figures corresponding to [*****], change by more or less\n",
    "[*****] with respect to the estimated values of the same parameters, considered at the time of commencement of the Term.\n",
    "As from the date this Agreement enters into force, the Parties agree to take into account the following basic operating parameters (the\n",
    "“Standard Operations”) as a reference for the above calculation:\n",
    "[*****]\n",
    "[*****]\n",
    "[*****]\"\"\"\n",
    "\n",
    "effective_date_and_duration = \"Amendment is effective starting on the date of its signature by both Parties.\"\n",
    "\n",
    "confidentiality = \"\"\"Confidential Information released by either of the Parties (the “Disclosing Party”) to the\n",
    "other Party (the “Receiving Party”) shall not be released in whole or in part to any third party:\n",
    "- Not to deliver, disclose or publish it to any third party including subsidiary companies and companies having an interest in its capital\n",
    "- Use Confidential Information solely for the purpose of this Amendment\n",
    "- Disclose the Confidential Information only to those of its direct employees\n",
    "- Not to duplicate the Confidential Information nor to copy\n",
    "\n",
    "Any Confidential Information shall remain the property of the Disclosing Party.\n",
    "\n",
    "The Receiving Party hereby acknowledges and recognises that Confidential Information is protected by copyright Laws and related\n",
    "international treaty provisions, as the case may be.\n",
    "\n",
    "This shall survive termination or expiry of this Amendment for a period of five (5) years following such End Date.\"\"\"\n",
    "\n",
    "governing_law = \"\"\"Pursuant to and in accordance with Section 5-1401 of the New York General Obligations Law.\n",
    "\n",
    "Arbitration: in the event of a dispute arising out of or relating to this Amendment, including without limitation disputes regarding the\n",
    "existence, validity or termination of this Amendment (a “Dispute”), either Party may notify such Dispute to the other through service of a\n",
    "written notice (the “Notice of Dispute”).\n",
    "\n",
    "Arbitration, and any proceedings, and meetings incidental to or related to the arbitration process, shall take place in New York.\n",
    "\n",
    "Arbitration shall be kept confidential and the existence of the proceeding and any element.\n",
    "\n",
    "During any period of negotiation or arbitration, the Parties shall continue to meet their respective obligations.\n",
    "\n",
    "Notwithstanding any provision of this the Parties may, at any time, seek and decide to settle a Dispute.\n",
    "\n",
    "Judgment upon any award may be entered in any court having jurisdiction.\n",
    "\n",
    "Recourse to jurisdictions is expressly excluded except as provided for in the ICC Rules of Conciliation and Arbitration.\"\"\"\n",
    "\n",
    "miscellaneous = \"\"\"Amendment contains the entire agreement between the Parties regarding the subject-matter.\n",
    "\n",
    "Amendment shall not be varied or modified except by a written document duly signed.\"\"\"\n",
    "\n",
    "contract = generate_contract(\n",
    "    contract_sections=[\n",
    "        definitions,\n",
    "        amendment,\n",
    "        effective_date_and_duration,\n",
    "        confidentiality,\n",
    "        governing_law,\n",
    "        miscellaneous,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(contract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"./data/tweets.csv.gz\", compression=\"gzip\", encoding=\"latin-1\", names=[\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"tweet\"])\n",
    "df_tweets = df_tweets.dropna()\n",
    "df_tweets = df_tweets.where(df_tweets.sentiment != 2)\n",
    "df_tweets[\"sentiment\"] = df_tweets[\"sentiment\"].map({4: 1, 0: 0})\n",
    "df_tweets_sampled = df_tweets.sample(n=10)\n",
    "df_tweets_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Take the following tweet and determine the sentiment of the review.\n",
    "\n",
    "Respond with 1 (positive) or 0 (negative).\n",
    "\n",
    "If you don't receive a tweet, respond with -1.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=128,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class Sentiment(BaseModel):\n",
    "    sentiment: int = Field(description=\"The sentiment of the tweet.\")\n",
    "\n",
    "sentiment_analysis_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"Tweet:\\n{tweet}\",\n",
    "    task_prompt_variables=[\"tweet\"],\n",
    "    tools=None,\n",
    "    output_format=Sentiment,\n",
    "    iterations=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentiment(tweet: str) -> int:\n",
    "    response = sentiment_analysis_agent.invoke({'tweet': tweet})\n",
    "    return response.final_answer['sentiment'] or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_sampled[\"prediction\"] = [classify_sentiment(tweet) for tweet in df_tweets_sampled.tweet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(df_tweets_sampled.sentiment, df_tweets_sampled.prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structuring Unstructured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./data/jobs\")\n",
    "filenames = [file.name for file in path.iterdir() if file.is_file()]\n",
    "filenames = random.sample(filenames, 5)\n",
    "\n",
    "jobs = []\n",
    "for filename in filenames:\n",
    "    file_path = path / filename\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "        content = file.read()\n",
    "        jobs.append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Take the following job and extract data about the job.\n",
    "\n",
    "Respond with the following extracted data:\n",
    "- job_title: The job title.\n",
    "- job_class_no: The job class code.\n",
    "- job_duties: The duties of the job.\n",
    "- open_date: When the position was opened. Format: DD-MM-YYYY.\n",
    "- salary: The salary ranges. Format: 'min salary to max salary'.\n",
    "- deadline: The application deadline. Format: DD-MM-YYYY.\n",
    "- application_form: The form of the application (e.g. online, fax, email).\n",
    "- where_to_apply: The url to apply at or location to send the fax or email address.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=2048,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class Job(BaseModel):\n",
    "    job_title: str = Field(description=\"The job title.\")\n",
    "    job_class_no: int = Field(description=\"The job class code.\")\n",
    "    job_duties: str = Field(description=\"The duties of the job.\")\n",
    "    open_date: str = Field(description=\"When the position was opened. Format: DD-MM-YYYY.\")\n",
    "    salary: list[str] = Field(description=\"A list of salary ranges. Format: 'min salary to max salary'.\")\n",
    "    deadline: str = Field(description=\"The application deadline. Format: DD-MM-YYYY\")\n",
    "    application_form: str = Field(description=\"The form of the application (e.g. online, fax, email).\")\n",
    "    where_to_apply: str = Field(description=\"The url to apply at or location to send the fax or email address.\")\n",
    "\n",
    "job_data_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"Job description:\\n{job}\",\n",
    "    task_prompt_variables=[\"job\"],\n",
    "    tools=None,\n",
    "    output_format=Job,\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jobs(jobs: list[str]) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for job in jobs:\n",
    "        response = job_data_agent.invoke({\"job\": job})\n",
    "        data.append(response.final_answer)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs = extract_jobs(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Unstructured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "        return content\n",
    "\n",
    "job1 = get_job(\"./data/jobs/ELECTRICAL ENGINEERING ASSOCIATE 7525 093016 REV 100416.txt\")\n",
    "job2 = get_job(\"./data/jobs/ELECTRICAL MECHANIC 3841 012017.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Take the following job and extract data about the job.\n",
    "\n",
    "Respond with the following extracted data:\n",
    "- job_title: The job title.\n",
    "- job_duties: The duties of the job.\n",
    "- salary: The salary ranges. Format: 'min salary to max salary'.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=1024,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class Job1(BaseModel):\n",
    "    job1_title: str = Field(description=\"The job title.\")\n",
    "    job1_duties: str = Field(description=\"The duties of the job.\")\n",
    "    salary1: list[str] = Field(description=\"A list of salary ranges. Format: 'min salary to max salary'.\")\n",
    "\n",
    "class Job2(BaseModel):\n",
    "    job2_title: str = Field(description=\"The job title.\")\n",
    "    job2_duties: str = Field(description=\"The duties of the job.\")\n",
    "    salary2: list[str] = Field(description=\"A list of salary ranges. Format: 'min salary to max salary'.\")\n",
    "\n",
    "job_agent1 = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"Job description:\\n{job1}\",\n",
    "    task_prompt_variables=[\"job1\"],\n",
    "    tools=None,\n",
    "    output_format=Job1,\n",
    "    iterations=10,\n",
    ")\n",
    "\n",
    "job_agent2 = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"Job description:\\n{job2}\",\n",
    "    task_prompt_variables=[\"job2\"],\n",
    "    tools=None,\n",
    "    output_format=Job2,\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Take the following 2 job descriptions and respond with the similarities and differences of the jobs.\"\n",
    "\n",
    "task_prompt = \"\"\"Compare the 2 given job descriptions:\n",
    "\n",
    "Job 1:\n",
    "Job title: {job1_title}\n",
    "Job duties:\n",
    "{job1_duties}\n",
    "Salary:\n",
    "{salary1}\n",
    "\n",
    "\n",
    "Job 2:\n",
    "Job title: {job2_title}\n",
    "Job duties:\n",
    "{job2_duties}\n",
    "Salary:\n",
    "{salary2}\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=1024,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class JobComparison(BaseModel):\n",
    "    similarities: str = Field(description=\"The job similarities.\")\n",
    "    differences: str = Field(description=\"The job differences.\")\n",
    "\n",
    "job_comparison_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=task_prompt,\n",
    "    task_prompt_variables=[\"job1_title\", \"job1_duties\", \"salary1\", \"job2_title\", \"job2_duties\", \"salary2\"],\n",
    "    tools=None,\n",
    "    output_format=JobComparison,\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = AgentChain(\n",
    "    chain=[job_agent1, job_agent2, job_comparison_agent],\n",
    "    chain_variables=[\"job1\", \"job2\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"job1\": job1, \"job2\": job2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"similarities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"differences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a Data Science agent, which helps the user solve machine learning problems.\n",
    "\n",
    "Respond with 1 of the following machine learning problems:\n",
    "- Classification\n",
    "- Regression\n",
    "- Clustering\n",
    "- Time series forecasting\"\"\"\n",
    "\n",
    "task_prompt = \"\"\"Choose the machine learning problem best suited for the following problem and dataset.\n",
    "\n",
    "Problem description:\n",
    "{problem_description}\n",
    "\n",
    "Dataset:\n",
    "Number of rows: {dataset_size}\n",
    "Schema:\n",
    "{dataset_schema}\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=128,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class ModelingProblem(BaseModel):\n",
    "    modeling_problem: str = Field(description=\"The machine learning problem.\")\n",
    "\n",
    "problem_finder_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=task_prompt,\n",
    "    task_prompt_variables=[\"problem_description\", \"dataset_size\", \"dataset_schema\"],\n",
    "    tools=None,\n",
    "    output_format=ModelingProblem,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a Data Science agent, which helps the user solve machine learning problems.\n",
    "\n",
    "You can solve machine learning problems for:\n",
    "- Classification\n",
    "- Regression\n",
    "- Clustering\n",
    "- Time series forecasting\n",
    "\n",
    "You have access to the following Python libraries:\n",
    "- pandas\n",
    "- numpy\n",
    "- scikit-learn\"\"\"\n",
    "\n",
    "task_prompt = \"\"\"Given the following machine learning problem, respond with Python code.\n",
    "\n",
    "Modeling problem: {modeling_problem}\n",
    "\n",
    "Dataset:\n",
    "Number of rows: {dataset_size}\n",
    "Schema:\n",
    "{dataset_schema}\n",
    "First 10 rows of dataset:\n",
    "{dataset_snippet}\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=2048,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class AutoMLCode(BaseModel):\n",
    "    code: str = Field(description=\"The Python machine learning code.\")\n",
    "\n",
    "ml_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=task_prompt,\n",
    "    task_prompt_variables=[\"modeling_problem\", \"dataset_size\", \"dataset_schema\", \"dataset_snippet\"],\n",
    "    tools=None,\n",
    "    output_format=AutoMLCode,\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_chain = AgentChain(\n",
    "    chain=[problem_finder_agent, ml_agent],\n",
    "    chain_variables=[\"problem_description\", \"dataset_size\", \"dataset_schema\", \"dataset_snippet\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_str = StringIO()\n",
    "df_tweets.info(buf=info_str)\n",
    "dataset_schema = info_str.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ml_chain.invoke({\n",
    "    \"problem_description\": \"I want to classify the sentiment of tweets.\",\n",
    "    \"dataset_size\": len(df_tweets),\n",
    "    \"dataset_schema\": dataset_schema,\n",
    "    \"dataset_snippet\": str(df_tweets.head(10).to_markdown())\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.final_answer[\"code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from language_models.tools.forecasting import get_earthquakes_data, ml_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Forecast(BaseModel):\n",
    "    start_time: str = Field(None, description='Limit to events on or after the specified start time. NOTE: All times use ISO8601 Date/Time format. Unless a timezone is specified, UTC is assumed.')\n",
    "    end_time: str = Field(None, description='Limit to events on or before the specified end time. NOTE: All times use ISO8601 Date/Time format. Unless a timezone is specified, UTC is assumed.')\n",
    "\n",
    "def forecast(start_time = None, end_time = None):\n",
    "    if start_time is None:\n",
    "        start_time = (datetime.now() - timedelta(days=30)).date()\n",
    "    if end_time is None:\n",
    "        end_time = (datetime.now().date())\n",
    "    df = get_earthquakes_data('https://earthquake.usgs.gov/fdsnws/event/1/query?', start_time, end_time)\n",
    "    df_pred = ml_model.predict(df)\n",
    "    return {'predictions': df_pred.to_dict(orient='records')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasting_tool = Tool(func=forecast, name='forecast', description='Test forecast model on real-time events.', args_schema=Forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prompt = \"\"\"Take the following question and determine the start and end time to respond with.\n",
    "\n",
    "Question:\n",
    "{question}\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=256,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class DateRange(BaseModel):\n",
    "    start_time: str = Field(description=\"Limit to events on or after the specified start time. NOTE: All times use ISO8601 Date/Time format. Unless a timezone is specified, UTC is assumed.\")\n",
    "    end_time: str = Field(description=\"Limit to events on or before the specified end time. NOTE: All times use ISO8601 Date/Time format. Unless a timezone is specified, UTC is assumed.\")\n",
    "\n",
    "time_wizard_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=\"\",\n",
    "    task_prompt=task_prompt,\n",
    "    task_prompt_variables=[\"question\"],\n",
    "    tools=[current_date_tool],\n",
    "    output_format=DateRange,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_chain = AgentChain(\n",
    "    chain=[time_wizard_agent, forecasting_tool],\n",
    "    chain_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = forecast_chain.invoke({\"question\": \"Run a forecast using the past week as data.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.final_answer[\"forecast\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI()\n",
    "\n",
    "class Question(BaseModel):\n",
    "    content: str\n",
    "\n",
    "class Forecast(BaseModel):\n",
    "    predictions: list[dict]\n",
    "\n",
    "@app.get(\"/forecast\")\n",
    "def forecast(question: Question) -> Forecast:\n",
    "    response = chain.invoke({\"question\": question.content})\n",
    "    return response.final_answer[\"forecast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    config = uvicorn.Config(app)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM-backed Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_agent.reset()\n",
    "problem_finder_agent.reset()\n",
    "ml_agent.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeAgent(BaseModel):\n",
    "    question: str = Field(description=\"The question regarding earthquakes.\")\n",
    "\n",
    "def answer_earthquake_questions(question: str) -> Any:\n",
    "    response = earthquake_agent.invoke({\"question\": question})\n",
    "    return response.final_answer\n",
    "\n",
    "earthquake_agent_tool = Tool(\n",
    "    func=answer_earthquake_questions,\n",
    "    name=\"Earthquake Agent\",\n",
    "    description=\"Use this tool to answer questions about earthquakes.\",\n",
    "    args_schema=EarthquakeAgent,\n",
    ")\n",
    "\n",
    "class MLAgent(BaseModel):\n",
    "    problem_description: str = Field(description=\"The user problem.\")\n",
    "    dataset_size: int = Field(description=\"The size of the dataset.\"),\n",
    "    dataset_schema: str = Field(description=\"The dataset schema or information.\"),\n",
    "    dataset_snippet: str = Field(description=\"The dataset snippet aka the first couple of rows of the dataset.\")\n",
    "\n",
    "def generate_ml_code(problem_description: str, dataset_size: int, dataset_schema: str, dataset_snippet: str) -> Any:\n",
    "    response = ml_chain.invoke({\n",
    "        \"problem_description\": problem_description,\n",
    "        \"dataset_size\": dataset_size,\n",
    "        \"dataset_schema\": dataset_schema,\n",
    "        \"dataset_snippet\": dataset_snippet,\n",
    "    })\n",
    "    return response.final_answer\n",
    "\n",
    "ml_agent_tool = Tool(\n",
    "    func=generate_ml_code,\n",
    "    name=\"ML Agent\",\n",
    "    description=\"Use this tool to generate machine learning code given a problem.\",\n",
    "    args_schema=MLAgent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an Agent that delegates tasks to other Agents by using the appropriate tools.\n",
    "\n",
    "Use the Earthquake Agent when the question is about earthquakes.\n",
    "\n",
    "Use the ML Agent when the user wants you to generate machine learning code.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4-32k',\n",
    "    max_tokens=4096,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"The final answer.\")\n",
    "\n",
    "almighty_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{prompt}\",\n",
    "    task_prompt_variables=[\"prompt\"],\n",
    "    tools=[earthquake_agent_tool, ml_agent_tool],\n",
    "    output_format=Output,\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = almighty_agent.invoke({\"prompt\": \"How many earthquakes have occurred for the past week with a magnitude of 5 or greater?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Give me code to train a model that predicts the sentiment of tweet.\n",
    "\n",
    "Dataset:\n",
    "Number of rows: {len(df_tweets)}\n",
    "Schema:\n",
    "{dataset_schema}\n",
    "First 10 rows of dataset:\n",
    "{df_tweets.head(10).to_markdown()}\"\"\"\n",
    "\n",
    "response = almighty_agent.invoke({\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
