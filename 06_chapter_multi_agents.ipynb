{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Chapter: Multi-Agents\n",
    "\n",
    "In our discussions so far, we've dived into the world of AI agents and AI agent workflows, exploring how we can leverage LLMs to utilize various tools effectively. This foundational knowledge has set the stage for a natural progression: enabling LLMs to collaborate with other LLMs. By establishing a structured mechanism for these interactions, we can significantly enhance the capabilities and applications of our AI systems.  \n",
    "\n",
    "To facilitate this collaboration, we can utilize a familiar structure, which we have already employed for tool usage:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "By turning other LLMs into tools, we ensure that our workflow remains streamlined and efficient. This approach simplifies the decision-making process for the primary LLM, as it doesn't need to distinguish between calling a tool and calling another LLM - it simply calls a tool. The neat encapsulation of LLMs as tools allows us to maintain clarity and uniformity in the responses we seek from these interactions.  For our showcase, we will demonstrate this concept by transforming an existing workflow into a tool. As we have previously defined the inputs that a workflow expects, this transition will be smooth and illustrative of the powerful potential of multi-agent environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, Field\n",
    "from loguru import logger\n",
    "from language_models.agent import (\n",
    "    Agent,\n",
    "    OutputType,\n",
    "    PromptingStrategy,\n",
    "    WorkflowAgentStep,\n",
    "    WorkflowFunctionStep,\n",
    "    WorkflowTransformationStep,\n",
    "    WorkflowOutput,\n",
    "    WorkflowStateManager,\n",
    ")\n",
    "from language_models.tools import Tool, current_date\n",
    "from language_models.models.llm import OpenAILanguageModel\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, format=\"{message}\", level=\"INFO\")\n",
    "\n",
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To integrate our workflow as a tool for use by an LLM, we simply add a new function that converts the workflow into an LLM-compatible tool, maintaining the defined inputs and utilizing the existing workflow execution structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Workflow(BaseModel):\n",
    "    \"\"\"Class that implements a workflow.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the workflow.\n",
    "        description: The description of what the workflow does.\n",
    "        steps: The steps of the workflow.\n",
    "        inputs: The workflow inputs.\n",
    "        output: The name of the step value to output.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    steps: list[WorkflowAgentStep | WorkflowFunctionStep | WorkflowTransformationStep]\n",
    "    inputs: type[BaseModel]\n",
    "    output: str\n",
    "    verbose: bool\n",
    "\n",
    "    def invoke(self, inputs: dict[str, Any]) -> WorkflowOutput:\n",
    "        \"\"\"Runs the workflow.\"\"\"\n",
    "        inputs = self.inputs.model_validate(inputs).model_dump()\n",
    "        state_manager = WorkflowStateManager(state=inputs)\n",
    "        for step in self.steps:\n",
    "            if self.verbose:\n",
    "                logger.opt(colors=True).info(f\"<b><fg #2D72D2>Running Step</fg #2D72D2></b>: {step.name}\")\n",
    "\n",
    "            output = step.invoke(state_manager.state, self.verbose)\n",
    "            state_manager.update(step.name, output)\n",
    "\n",
    "        output = state_manager.state.get(self.output)\n",
    "        if self.verbose:\n",
    "            logger.opt(colors=True).success(f\"<b><fg #32A467>Workflow Output</fg #32A467></b>: {output}\")\n",
    "\n",
    "        return WorkflowOutput(inputs=inputs, output=output)\n",
    "\n",
    "    def as_tool(self) -> Tool:\n",
    "        \"\"\"Converts the workflow into an LLM tool.\"\"\"\n",
    "        return Tool(\n",
    "            function=lambda **inputs: self.invoke(inputs).output,\n",
    "            name=self.name,\n",
    "            description=self.description,\n",
    "            args_schema=self.inputs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setup, we first define individual workflows and tools that handle specific tasks, such as extracting numbers from text and querying earthquake data. By converting these workflows into tools, we can easily integrate them into an AI agent. Finally, we combine these agents into a chat agent that can leverage the capabilities of all the defined workflows and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract all numbers from the user's input text.\"\"\"\n",
    "\n",
    "extractor_agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{prompt}\",\n",
    "    prompt_variables=[\"prompt\"],\n",
    "    output_type=OutputType.ARRAY_INTEGER,\n",
    "    prompting_strategy=PromptingStrategy.SINGLE_COMPLETION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_step = WorkflowAgentStep(name=\"numbers\", agent=extractor_agent)\n",
    "\n",
    "class Function(BaseModel):\n",
    "    numbers: list[int]\n",
    "\n",
    "function_step = WorkflowFunctionStep(name=\"sort\", inputs=Function, function=lambda numbers: sorted(numbers))\n",
    "\n",
    "filter_step = WorkflowTransformationStep(name=\"numbers_greater_10\", input_field=\"sort\", transformation=\"filter\", function=lambda number: number > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt(BaseModel):\n",
    "    prompt: str = Field(description=\"The user prompt\")\n",
    "\n",
    "extract_numbers_workflow = Workflow(\n",
    "    name=\"Find numbers greater than 10\",\n",
    "    description=\"Extracts numbers from a given text\",\n",
    "    steps=[agent_step, function_step, filter_step],\n",
    "    inputs=Prompt,\n",
    "    output=\"numbers_greater_10\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class USGeopoliticalSurveyEarthquakeAPI(BaseModel):\n",
    "    \"\"\"Class that implements the API interface.\"\"\"\n",
    "\n",
    "    start_time: str = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Limit to events on or after the specified start time. NOTE: All times use ISO8601 Date/Time format.\"\n",
    "            + \" Unless a timezone is specified, UTC is assumed.\"\n",
    "        ),\n",
    "    )\n",
    "    end_time: str = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Limit to events on or before the specified end time. NOTE: All times use ISO8601 Date/Time format.\"\n",
    "            + \" Unless a timezone is specified, UTC is assumed.\"\n",
    "        ),\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        20000,\n",
    "        description=(\n",
    "            \"Limit the results to the specified number of events. NOTE: The service limits queries to 20000,\"\n",
    "            + \" and any that exceed this limit will generate a HTTP response code 400 Bad Request.\"\n",
    "        ),\n",
    "    )\n",
    "    min_depth: int = Field(\n",
    "        -100,\n",
    "        description=\"Limit to events with depth more than the specified minimum.\",\n",
    "    )\n",
    "    max_depth: int = Field(\n",
    "        1000,\n",
    "        description=\"Limit to events with depth less than the specified maximum.\",\n",
    "    )\n",
    "    min_magnitude: int = Field(\n",
    "        None,\n",
    "        description=\"Limit to events with a magnitude larger than the specified minimum.\",\n",
    "    )\n",
    "    max_magnitude: int = Field(\n",
    "        None,\n",
    "        description=\"Limit to events with a magnitude smaller than the specified maximum.\",\n",
    "    )\n",
    "    alert_level: str = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Limit to events with a specific PAGER alert level.\"\n",
    "            + \" The allowed values are: alert_level=green Limit to events with PAGER\"\n",
    "            + ' alert level \"green\". alert_level=yellow Limit to events with PAGER alert level \"yellow\".'\n",
    "            + ' alert_level=orange Limit to events with PAGER alert level \"orange\".'\n",
    "            + ' alert_level=red Limit to events with PAGER alert level \"red\".'\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def get_earthquakes(\n",
    "    endpoint: str,\n",
    "    start_time: datetime = (datetime.now() - timedelta(days=30)).date(),\n",
    "    end_time: datetime = datetime.now().date(),\n",
    "    limit: int = 20000,\n",
    "    min_depth: int = -100,\n",
    "    max_depth: int = 1000,\n",
    "    min_magnitude: int | None = None,\n",
    "    max_magnitude: int | None = None,\n",
    "    alert_level: str | None = None,\n",
    ") -> Any:\n",
    "    params = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": start_time,\n",
    "        \"endtime\": end_time,\n",
    "        \"limit\": limit,\n",
    "        \"mindepth\": min_depth,\n",
    "        \"maxdepth\": max_depth,\n",
    "        \"minmagnitude\": min_magnitude,\n",
    "        \"maxmagnitude\": max_magnitude,\n",
    "        \"alertlevel\": alert_level,\n",
    "        \"eventtype\": \"earthquake\",\n",
    "    }\n",
    "    response = requests.get(\n",
    "        f\"https://earthquake.usgs.gov/fdsnws/event/1/{endpoint}\",\n",
    "        params=params,\n",
    "        timeout=None,\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "def query_earthquakes(\n",
    "    start_time: datetime = (datetime.now() - timedelta(days=30)).date(),\n",
    "    end_time: datetime = datetime.now().date(),\n",
    "    limit: int = 20000,\n",
    "    min_depth: int = -100,\n",
    "    max_depth: int = 1000,\n",
    "    min_magnitude: int | None = None,\n",
    "    max_magnitude: int | None = None,\n",
    "    alert_level: str | None = None,\n",
    ") -> Any:\n",
    "    return get_earthquakes(\n",
    "        endpoint=\"query\",\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        limit=limit,\n",
    "        min_depth=min_depth,\n",
    "        max_depth=max_depth,\n",
    "        min_magnitude=min_magnitude,\n",
    "        max_magnitude=max_magnitude,\n",
    "        alert_level=alert_level,\n",
    "    )\n",
    "\n",
    "def count_earthquakes(\n",
    "    start_time: datetime = (datetime.now() - timedelta(days=30)).date(),\n",
    "    end_time: datetime = datetime.now().date(),\n",
    "    limit: int = 20000,\n",
    "    min_depth: int = -100,\n",
    "    max_depth: int = 1000,\n",
    "    min_magnitude: int | None = None,\n",
    "    max_magnitude: int | None = None,\n",
    "    alert_level: str | None = None,\n",
    ") -> Any:\n",
    "    return get_earthquakes(\n",
    "        endpoint=\"count\",\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        limit=limit,\n",
    "        min_depth=min_depth,\n",
    "        max_depth=max_depth,\n",
    "        min_magnitude=min_magnitude,\n",
    "        max_magnitude=max_magnitude,\n",
    "        alert_level=alert_level,\n",
    "    )\n",
    "\n",
    "query_earthquakes_tool = Tool(\n",
    "    function=query_earthquakes,\n",
    "    name=\"Query Earthquakes\",\n",
    "    description=\"Use this tool to search recent earthquakes\",\n",
    "    args_schema=USGeopoliticalSurveyEarthquakeAPI,\n",
    ")\n",
    "\n",
    "count_earthquakes_tool = Tool(\n",
    "    function=count_earthquakes,\n",
    "    name=\"Count Earthquakes\",\n",
    "    description=\"Use this tool to count and aggregate recent earthquakes\",\n",
    "    args_schema=USGeopoliticalSurveyEarthquakeAPI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an United States Geological Survey expert who can answer questions regarding earthquakes.\"\n",
    "\n",
    "earthquake_agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{question}\",\n",
    "    prompt_variables=[\"question\"],\n",
    "    output_type=OutputType.STRING,\n",
    "    tools=[current_date, count_earthquakes_tool, query_earthquakes_tool],\n",
    "    prompting_strategy=PromptingStrategy.CHAIN_OF_THOUGHT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeQuery(BaseModel):\n",
    "    question: str = Field(description=\"The earthquake related user question\")\n",
    "\n",
    "earthquake_workflow = Workflow(\n",
    "    name=\"Earthquake Agent\",\n",
    "    description=\"Allows you to answer earthquake related questions\",\n",
    "    inputs=EarthquakeQuery,\n",
    "    output=\"earthquake\",\n",
    "    steps=[WorkflowAgentStep(name=\"earthquake\", agent=earthquake_agent)],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{prompt}\",\n",
    "    prompt_variables=[\"prompt\"],\n",
    "    tools=[extract_numbers_workflow.as_tool(), earthquake_workflow.as_tool()],\n",
    "    output_type=OutputType.STRING,\n",
    "    prompting_strategy=PromptingStrategy.CHAIN_OF_THOUGHT,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By invoking the agent with the prompt about today's earthquakes, we instruct it to use the earthquake agent encapsulated as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: To answer this question, I need to use the Earthquake Agent tool which can provide information about earthquake occurrences.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Earthquake Agent\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {'question': 'How many earthquakes happened today?'}\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: earthquake\n",
      "\u001b[1m\u001b[38;2;236;154;60mAgent Input\u001b[0m\u001b[1m\u001b[0m: {'question': 'How many earthquakes happened today?'}\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: To answer this question, I need to count the number of earthquakes that occurred today. I can use the \"Count Earthquakes\" tool for this. I need to specify the start time as the beginning of today and the end time as the current time.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Current Date\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {}\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: 2024-08-12 12:26:53.814336\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: Now that I have the current date and time, I can use this information to set the start time and end time for the \"Count Earthquakes\" tool. The start time should be the beginning of today, which is \"2024-08-12 00:00:00\", and the end time should be the current time, which is \"2024-08-12 12:26:53.814336\".\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Count Earthquakes\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {'start_time': '2024-08-12 00:00:00', 'end_time': '2024-08-12 12:26:53.814336'}\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: {'count': 90, 'maxAllowed': 20000}\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The tool output indicates that 90 earthquakes have occurred today.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: There have been 90 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;236;154;60mAgent Output\u001b[0m\u001b[1m\u001b[0m: There have been 90 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;50;164;103mWorkflow Output\u001b[0m\u001b[1m\u001b[0m: There have been 90 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: There have been 90 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The tool has provided the answer to the user's question.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: There have been 90 earthquakes today.\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"prompt\": \"How many earthquakes happened today?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By invoking the agent with the prompt about a hiking trip, we instruct it to use the numbers extraction workflow encapsulated as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: To extract all numbers greater than 10 from the given context, I need to use the \"Find numbers greater than 10\" tool.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Find numbers greater than 10\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {'prompt': \"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM. By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C. We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"}\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: numbers\n",
      "\u001b[1m\u001b[38;2;236;154;60mAgent Input\u001b[0m\u001b[1m\u001b[0m: {'prompt': \"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM. By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C. We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"}\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "\u001b[1m\u001b[38;2;236;154;60mAgent Output\u001b[0m\u001b[1m\u001b[0m: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: sort\n",
      "\u001b[1m\u001b[38;2;236;154;60mFunction Input\u001b[0m\u001b[1m\u001b[0m: {'numbers': [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]}\n",
      "\u001b[1m\u001b[38;2;236;154;60mFunction Output\u001b[0m\u001b[1m\u001b[0m: [2, 5, 5, 6, 6, 7, 10, 12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: numbers_greater_10\n",
      "\u001b[1m\u001b[38;2;236;154;60mTransformation Input\u001b[0m\u001b[1m\u001b[0m: {'sort': [2, 5, 5, 6, 6, 7, 10, 12, 12, 15, 4401]}\n",
      "\u001b[1m\u001b[38;2;236;154;60mTransformation Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;50;164;103mWorkflow Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The tool has successfully extracted all the numbers greater than 10 from the given context.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: The numbers greater than 10 in the given context are 12, 12, 15, and 4401.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Extract all numbers > 10 from this context:\n",
    "\n",
    "Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C.\n",
    "\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = agent.invoke({\"prompt\": prompt})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
