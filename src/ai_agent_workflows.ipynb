{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Chapter: AI Agent Workflows\n",
    "\n",
    "When we talk about LLM-powered AI agent workflows, we're referring to the integration of LLMs with other AI models, tools, and systems to create a seamless, end-to-end process for tackling complex tasks. These workflows enable AI agents to leverage the strengths of different technologies, ensuring they can handle a diverse range of tasks involving both unstructured and structured data. LLMs are exceptional at working with unstructured data like text, audio transcripts, and social media posts. Effective AI workflows often involve processing structured data, such as tables, spreadsheets, and databases. Integrations with tools like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from typing import Any, Callable, Literal\n",
    "from functools import reduce\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from loguru import logger\n",
    "\n",
    "from language_models.agent import Agent, OutputType, PromptingStrategy\n",
    "from language_models.models.llm import OpenAILanguageModel\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, format=\"{message}\", level=\"INFO\")\n",
    "\n",
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=250,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowStepOutput(BaseModel):\n",
    "    \"\"\"Class that represents the output of a step.\"\"\"\n",
    "\n",
    "    inputs: dict[str, Any]\n",
    "    output: (\n",
    "        str | int | float | dict | BaseModel | list[str] | list[int] | list[float] | list[dict] | list[BaseModel] | None\n",
    "    )\n",
    "\n",
    "class WorkflowFunctionStep(BaseModel):\n",
    "    \"\"\"Class that implements a function step.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the step.\n",
    "        inputs: The Pydantic model that represents the input arguments.\n",
    "        function: The function that will be invoked when calling this step.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    inputs: type[BaseModel]\n",
    "    function: Callable[[Any], Any]\n",
    "\n",
    "    def invoke(self, inputs: dict[str, Any], verbose: bool) -> WorkflowStepOutput:\n",
    "        inputs = {key: value for key, value in inputs.items() if key in self.inputs.model_fields}\n",
    "        inputs = self.inputs.model_validate(inputs).model_dump()\n",
    "        if verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Function Input</fg #EC9A3C></b>: {inputs}\")\n",
    "\n",
    "        output = self.function(**inputs)\n",
    "        if verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Function Output</fg #EC9A3C></b>: {output}\")\n",
    "\n",
    "        return WorkflowStepOutput(inputs=inputs, output=output)\n",
    "\n",
    "class WorkflowAgentStep(BaseModel):\n",
    "    \"\"\"Class that implements an agent step.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the step.\n",
    "        agent: The agent that will be invoked when calling this step.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    agent: Agent\n",
    "\n",
    "    def invoke(self, inputs: dict[str, Any], verbose: bool) -> WorkflowStepOutput:\n",
    "        inputs = {variable: inputs.get(variable) for variable in self.agent.prompt_variables}\n",
    "        if verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Agent Input</fg #EC9A3C></b>: {inputs}\")\n",
    "\n",
    "        output = self.agent.invoke(inputs)\n",
    "        if verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Agent Output</fg #EC9A3C></b>: {output.final_answer}\")\n",
    "\n",
    "        return WorkflowStepOutput(inputs=inputs, output=output.final_answer)\n",
    "\n",
    "class WorkflowTransformationStep(BaseModel):\n",
    "    \"\"\"Class that implements a transformation step.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the step.\n",
    "        input_field: The name of the field values to transform.\n",
    "        transformation: The transformation to apply (can be map, filter, reduce).\n",
    "        function: The function used for the transformation.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    input_field: str\n",
    "    transformation: Literal[\"map\", \"filter\", \"reduce\"]\n",
    "    function: Callable[[Any], Any]\n",
    "\n",
    "    def invoke(self, inputs: dict[str, Any], verbose: bool) -> WorkflowStepOutput:\n",
    "        values = inputs[self.input_field]\n",
    "        if verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Transformation Input</fg #EC9A3C></b>: {values}\")\n",
    "\n",
    "        if self.transformation == \"map\":\n",
    "            transformed_values = map(self.function, values)\n",
    "            output = list(transformed_values) if isinstance(values, list) else dict(transformed_values)\n",
    "        elif self.transformation == \"filter\":\n",
    "            transformed_values = filter(self.function, values)\n",
    "            output = list(transformed_values) if isinstance(values, list) else dict(transformed_values)\n",
    "        else:\n",
    "            output = reduce(self.function, values)\n",
    "\n",
    "        if verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Transformation Output</fg #EC9A3C></b>: {output}\")\n",
    "\n",
    "        return WorkflowStepOutput(inputs={self.input_field: values}, output=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowStateManager(BaseModel):\n",
    "    \"\"\"Class that implements a state manager.\"\"\"\n",
    "\n",
    "    state: dict[str, Any]\n",
    "\n",
    "    def update(self, name: str, step: WorkflowStepOutput) -> None:\n",
    "        \"\"\"Updates the state values.\"\"\"\n",
    "        self.state[name] = step.output\n",
    "\n",
    "class WorkflowOutput(BaseModel):\n",
    "    \"\"\"Class that represents the workflow output.\"\"\"\n",
    "\n",
    "    inputs: dict[str, Any]\n",
    "    output: (\n",
    "        str\n",
    "        | int\n",
    "        | float\n",
    "        | dict[str, Any]\n",
    "        | BaseModel\n",
    "        | list[str]\n",
    "        | list[int]\n",
    "        | list[float]\n",
    "        | list[dict[str, Any]]\n",
    "        | list[BaseModel]\n",
    "        | None\n",
    "    )\n",
    "\n",
    "class Workflow(BaseModel):\n",
    "    \"\"\"Class that implements a workflow.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the workflow.\n",
    "        description: The description of what the workflow does.\n",
    "        steps: The steps of the workflow.\n",
    "        inputs: The workflow inputs.\n",
    "        output: The name of the step value to output.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    steps: list[WorkflowAgentStep | WorkflowFunctionStep | WorkflowTransformationStep]\n",
    "    inputs: type[BaseModel]\n",
    "    output: str\n",
    "    verbose: bool\n",
    "\n",
    "    def invoke(self, inputs: dict[str, Any]) -> WorkflowOutput:\n",
    "        \"\"\"Runs the workflow.\"\"\"\n",
    "        inputs = self.inputs.model_validate(inputs).model_dump()\n",
    "        if self.verbose:\n",
    "            logger.opt(colors=True).info(f\"<b><fg #EC9A3C>Workflow Input</fg #EC9A3C></b>: {inputs}\")\n",
    "\n",
    "        state_manager = WorkflowStateManager(state=inputs)\n",
    "        for step in self.steps:\n",
    "            if self.verbose:\n",
    "                logger.opt(colors=True).info(f\"<b><fg #2D72D2>Running Step</fg #2D72D2></b>: {step.name}\")\n",
    "\n",
    "            output = step.invoke(state_manager.state, self.verbose)\n",
    "            state_manager.update(step.name, output)\n",
    "\n",
    "        output = state_manager.state.get(self.output)\n",
    "        if self.verbose:\n",
    "            logger.opt(colors=True).success(f\"<b><fg #32A467>Workflow Output</fg #32A467></b>: {output}\")\n",
    "\n",
    "        return WorkflowOutput(inputs=inputs, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract all numbers from the user's input text.\"\"\"\n",
    "\n",
    "agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{prompt}\",\n",
    "    prompt_variables=[\"prompt\"],\n",
    "    output_type=OutputType.ARRAY_INTEGER,\n",
    "    prompting_strategy=PromptingStrategy.SINGLE_COMPLETION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_step = WorkflowAgentStep(name=\"numbers\", agent=agent)\n",
    "\n",
    "class Function(BaseModel):\n",
    "    numbers: list[int]\n",
    "\n",
    "function_step = WorkflowFunctionStep(name=\"sort\", inputs=Function, function=lambda numbers: sorted(numbers))\n",
    "\n",
    "filter_step = WorkflowTransformationStep(name=\"numbers_greater_10\", input_field=\"sort\", transformation=\"filter\", function=lambda number: number > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt(BaseModel):\n",
    "    prompt: str = Field(description=\"The user prompt\")\n",
    "\n",
    "workflow = Workflow(\n",
    "    name=\"Data Extraction\",\n",
    "    description=\"Extracts numbers from a given text\",\n",
    "    steps=[agent_step, function_step, filter_step],\n",
    "    inputs=Prompt,\n",
    "    output=\"numbers_greater_10\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;2;236;154;60mWorkflow Input\u001b[0m\u001b[1m\u001b[0m: {'prompt': \"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\\n\\nBy noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12째C.\\n\\nWe camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"}\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: numbers\n",
      "\u001b[1m\u001b[38;2;236;154;60mAgent Input\u001b[0m\u001b[1m\u001b[0m: {'prompt': \"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\\n\\nBy noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12째C.\\n\\nWe camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"}\n",
      "Prompt: Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
      "\n",
      "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12째C.\n",
      "\n",
      "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\n",
      "Raw Output: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "Final Answer: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "\u001b[1m\u001b[38;2;236;154;60mAgent Output\u001b[0m\u001b[1m\u001b[0m: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: sort\n",
      "\u001b[1m\u001b[38;2;236;154;60mFunction Input\u001b[0m\u001b[1m\u001b[0m: {'numbers': [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]}\n",
      "\u001b[1m\u001b[38;2;236;154;60mFunction Output\u001b[0m\u001b[1m\u001b[0m: [2, 5, 5, 6, 6, 7, 10, 12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;45;114;210mRunning Step\u001b[0m\u001b[1m\u001b[0m: numbers_greater_10\n",
      "\u001b[1m\u001b[38;2;236;154;60mTransformation Input\u001b[0m\u001b[1m\u001b[0m: [2, 5, 5, 6, 6, 7, 10, 12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;236;154;60mTransformation Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;50;164;103mWorkflow Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12째C.\n",
    "\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = workflow.invoke({\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 12, 15, 4401]\n"
     ]
    }
   ],
   "source": [
    "print(output.output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
