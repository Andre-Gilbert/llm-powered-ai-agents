{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 03: Structured Outputs\n",
    "\n",
    "Structured outputs are useful when you need your data to fit a specific format, ensuring it's easy to process, analyze, or store. Think of it like this: instead of getting a blob of text, you get neat, well-organized data that can be directly used in your applications. Here are some common output types that LLMs can generate:\n",
    "- **String**: Simple text, like \"Hello\" or \"World\". \n",
    "- **Integer**: Whole numbers, such as `123` or `-456`. \n",
    "- **Float**: Numbers with decimals, like `3.14` or `-0.001`. \n",
    "- **Boolean**: True/False values, useful for binary decisions. \n",
    "- **Binary**: Data in binary format, something like `10101010`. \n",
    "- **Date**: Calendar dates in formats like `YYYY-MM-DD`. \n",
    "- **Timestamp**: Specific points in time like `2023-10-05 14:48:00`.\n",
    "- **Array**: Lists of elements, which can be strings, integers, floats, structs, or even other arrays.\n",
    "- **Struct**: Collections of key-value pairs. \n",
    "- **Object**: Objects with specified attributes. \n",
    "\n",
    "By generating structured outputs, LLMs can: \n",
    "- **Integrate with systems**: Easily slot into existing databases, APIs, or other software. \n",
    "- **Enable automation**: Power automated reporting, decision-making engines, and other workflows. \n",
    "- **Enhance accuracy**: Ensure data consistency and integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dirtyjson as json\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, EmailStr, Field, ValidationError\n",
    "from datetime import datetime\n",
    "from language_models.models.llm import OpenAILanguageModel, ChatMessage, ChatMessageRole\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a sense of structured outputs, we will walk through a few examples. When the final answer from the LLM is successfully parsed, it is crucial to validate the output to ensure it matches the expected output type. If the validation is successful, we can return the response to the user. If not, we ask the LLM to correct its output if we use Chain-of-Thought prompting.\n",
    "\n",
    "**String**\n",
    "\n",
    "The standard output type for LLM applications is typically a string. However, in certain cases, you might only want the LLM to output a single word or a brief phrase. Additionally, it's important to instruct the LLM on how to handle edge cases - situations where the input does not match the expected input described to the model. For string outputs, this can involve responding with an empty string when the expected input format is not met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a string\"\"\"\n",
    "\n",
    "prompt = \"What is the capital city of France?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integer**\n",
    "\n",
    "For integer output types, the LLM should be instructed to provide a numerical response within a specified range, extract numbers from the input text, or output a value based on the results from a tool it uses. In the event of unexpected input, it should return a default value, such as 0 or -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be an integer\"\"\"\n",
    "\n",
    "prompt = \"How many continents are there on Earth?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = int(output)\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Float**\n",
    "\n",
    "For float output types, the LLM should generate a numerical response with decimal precision, either within a specified range or based on extracted data from input text or tool outputs. In case of unexpected input, it should return a default value, like 0.0 or -1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be an float\"\"\"\n",
    "\n",
    "prompt = \"What is the value of Pi up to two decimal places?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = float(output)\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boolean**\n",
    "\n",
    "For boolean output types, the LLM should return \"true\" or \"false\" based on the evaluation of input data or tool outputs. For example, when asked whether the contractor has violated terms, the response should be \"true\" if there is evidence of a violation and \"false\" otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a boolean (true, false)\"\"\"\n",
    "\n",
    "prompt = \"Is the number 5 greater than 3?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if output.lower() == \"true\":\n",
    "    print(True)\n",
    "elif output.lower() == \"false\":\n",
    "    print(False)\n",
    "else:\n",
    "    print(\"Could not parse output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary**\n",
    "\n",
    "A binary string output in LLM applications can offer a compact, universally understandable format for encoding data, which is particularly useful for tasks requiring data serialization, cryptographic applications, or low-level hardware communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a binary string\"\"\"\n",
    "\n",
    "prompt = \"What is the binary representation of the number 15?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "if bool(re.fullmatch(r\"[01]+\", output)):\n",
    "    print(output)\n",
    "else:\n",
    "    print(\"Could not parse output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date**\n",
    "\n",
    "A date output type is essential for accurately managing and processing time-related information, facilitating tasks such as scheduling, temporal queries, and event tracking. It ensures consistent and standardized handling of dates, which is crucial for applications in domains like finance, healthcare, and project management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract the date from the user's input text.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a date with the format: %Y-%m-%d\"\"\"\n",
    "\n",
    "prompt = \"We are excited to announce that our annual company retreat will be held on April 15, 2024. This event will be a great opportunity for team building and strategic planning.\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = datetime.strptime(output, \"%Y-%m-%d\")\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Timestamp**\n",
    "\n",
    "A timestamp output type is valuable for precisely recording and managing events with specific dates and times, which is crucial for activities like logging transactions, tracking changes, and conducting time-sensitive data analysis. This precision supports robust auditing, accurate scheduling, and reliable temporal sequencing across various use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract the date from the user's input text.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a date with the format: %Y-%m-%d %H:%M:%S\"\"\"\n",
    "\n",
    "prompt = \"We are excited to announce that our annual company retreat will be held on April 15, 2024. This event will be a great opportunity for team building and strategic planning.\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = datetime.strptime(output, \"%Y-%m-%d %H:%M:%S\")\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Array**\n",
    "\n",
    "In LLM applications, an array output type is crucial for efficiently managing sequences of tokens, data structures, or lists of generated items, enabling the model to handle complex outputs such as ordered collections, tables, and multi-step instructions more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract all numbers from the user's input text.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be an array of integers\"\"\"\n",
    "\n",
    "prompt = \"\"\"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C.\n",
    "\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = json.loads(output)\n",
    "    output = list(output)\n",
    "    if all(isinstance(entry, int) for entry in output):\n",
    "        print(output)\n",
    "    else:\n",
    "        raise ValueError(\"Could not parse output\")\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Struct**\n",
    "\n",
    "A struct output type groups different kinds of data as key-value pairs under one name, making it easier to organize and access complex information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_from_args(args: dict[str, Any]) -> dict[str, Any]:\n",
    "    template = '    \"{field}\": {field_type}, # {description}'\n",
    "    fields = []\n",
    "    for field, details in args.items():\n",
    "        field_type = details.get(\"type\")\n",
    "        items_type = details.get(\"items\", {}).get(\"type\")\n",
    "        format_type = details.get(\"items\", {}).get(\"format\") or details.get(\"format\")\n",
    "        description = details.get(\"description\")\n",
    "        if field_type in \"string\":\n",
    "            if format_type == \"date\":\n",
    "                fields.append(template.format(field=field, field_type=\"<date>\", description=description))\n",
    "            elif format_type == \"date-time\":\n",
    "                fields.append(template.format(field=field, field_type=\"<timestamp>\", description=description))\n",
    "            elif format_type == \"email\":\n",
    "                fields.append(template.format(field=field, field_type=\"<email>\", description=description))\n",
    "            else:\n",
    "                fields.append(template.format(field=field, field_type=\"<string>\", description=description))\n",
    "        elif field_type == \"integer\":\n",
    "            fields.append(template.format(field=field, field_type=\"<integer>\", description=description))\n",
    "        elif field_type == \"number\":\n",
    "            fields.append(template.format(field=field, field_type=\"<float>\", description=description))\n",
    "        elif field_type == \"boolean\":\n",
    "            fields.append(template.format(field=field, field_type=\"<boolean>\", description=description))\n",
    "        elif field_type == \"array\":\n",
    "            if items_type == \"string\":\n",
    "                if format_type == \"date\":\n",
    "                    fields.append(template.format(field=field, field_type=\"<array of dates>\", description=description))\n",
    "                elif format_type == \"date-time\":\n",
    "                    fields.append(template.format(field=field, field_type=\"<array of timestamps>\", description=description))\n",
    "                elif format_type == \"email\":\n",
    "                    fields.append(template.format(field=field, field_type=\"<array of emails>\", description=description))\n",
    "                else:\n",
    "                    fields.append(template.format(field=field, field_type=\"<array of strings>\", description=description))\n",
    "            elif items_type == \"integer\":\n",
    "                fields.append(template.format(field=field, field_type=\"<array of integers>\", description=description))\n",
    "            elif items_type == \"number\":\n",
    "                fields.append(template.format(field=field, field_type=\"<array of floats>\", description=description))\n",
    "    schema = \"\\n\".join(fields)\n",
    "    return \"\\n\".join([\"{\", schema, \"}\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"to\": <array of emails>, # List of people to send it to\n",
      "    \"subject\": <string>, # Subject of the email\n",
      "    \"body\": <string>, # Body of the email\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "class Email(BaseModel):\n",
    "    to: list[EmailStr] = Field(description=\"List of people to send it to\")\n",
    "    subject: str = Field(description=\"Subject of the email\")\n",
    "    body: str = Field(description=\"Body of the email\")\n",
    "\n",
    "args = Email.model_json_schema()[\"properties\"]\n",
    "output_schema = get_schema_from_args(args)\n",
    "print(output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"to\": [\"johndoe@example.com\", \"janedoe@example.com\", \"alice.smith@company.org\"],\n",
      "    \"subject\": \"Weekend Hiking Trip Recap\",\n",
      "    \"body\": \"Hello all,\\n\\nI hope this email finds you well. I am writing to recap our amazing hiking trip last weekend.\\n\\nWe started our 15-kilometer hike at 7 AM. By noon, we had covered 10 kilometers. We reached the summit of Mount Elbert, standing tall at 4,401 meters, by 2 PM. The weather was quite pleasant with a temperature of 12°C.\\n\\nWe set up our camp 5 kilometers away from the summit by 6 PM. We were joined by 12 other fellow hikers at the campsite. After spending a night under the stars, we packed up and returned home by 5 PM the next day.\\n\\nIt was an unforgettable experience and I am looking forward to our next adventure.\\n\\nBest,\\n[Your Name]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Write an email.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a JSON format with the keyword arguments:\n",
    "{output_schema}\"\"\"\n",
    "\n",
    "prompt = \"\"\"Send the email to:\n",
    "1. johndoe@example.com\n",
    "2. janedoe@example.com\n",
    "3. alice.smith@company.org\n",
    "\n",
    "Here is what we did: Weekend Hiking Trip Recap\n",
    "\n",
    "Here is some context:\n",
    "Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C.\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': ['johndoe@example.com', 'janedoe@example.com', 'alice.smith@company.org'], 'subject': 'Weekend Hiking Trip Recap', 'body': 'Hello all,\\n\\nI hope this email finds you well. I am writing to recap our amazing hiking trip last weekend.\\n\\nWe started our 15-kilometer hike at 7 AM. By noon, we had covered 10 kilometers. We reached the summit of Mount Elbert, standing tall at 4,401 meters, by 2 PM. The weather was quite pleasant with a temperature of 12°C.\\n\\nWe set up our camp 5 kilometers away from the summit by 6 PM. We were joined by 12 other fellow hikers at the campsite. After spending a night under the stars, we packed up and returned home by 5 PM the next day.\\n\\nIt was an unforgettable experience and I am looking forward to our next adventure.\\n\\nBest,\\n[Your Name]'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = json.loads(output)\n",
    "    output = Email.model_validate(output)\n",
    "    print(output.model_dump())\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Object**\n",
    "\n",
    "An object output type enables structured data representation, making it easier to parse, manipulate, and integrate with other systems or workflows, thereby improving efficiency and reducing the potential for errors in downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: ['johndoe@example.com', 'janedoe@example.com', 'alice.smith@company.org']\n",
      "Subject: Weekend Hiking Trip Recap\n",
      "Body: Hello all,\n",
      "\n",
      "I hope this email finds you well. I am writing to recap our amazing hiking trip last weekend.\n",
      "\n",
      "We started our 15-kilometer hike at 7 AM. By noon, we had covered 10 kilometers. We reached the summit of Mount Elbert, standing tall at 4,401 meters, by 2 PM. The weather was quite pleasant with a temperature of 12°C.\n",
      "\n",
      "We set up our camp 5 kilometers away from the summit by 6 PM. We were joined by 12 other fellow hikers at the campsite. After spending a night under the stars, we packed up and returned home by 5 PM the next day.\n",
      "\n",
      "It was an unforgettable experience and I am looking forward to our next adventure.\n",
      "\n",
      "Best,\n",
      "[Your Name]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = Email.model_validate(output)\n",
    "    print(f\"To: {output.to}\")\n",
    "    print(f\"Subject: {output.subject}\")\n",
    "    print(f\"Body: {output.body}\")\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
