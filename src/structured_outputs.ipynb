{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Chapter: Structured Outputs\n",
    "\n",
    "Structured outputs are useful when you need your data to fit a specific format, ensuring it's easy to process, analyze, or store. Think of it like this: instead of getting a blob of text, you get neat, well-organized data that can be directly used in your applications.\n",
    "\n",
    "Here are some common types of structured outputs that LLMs can generate:\n",
    "- **String**: Simple text, like \"Hello\" or \"World\". \n",
    "- **Integer**: Whole numbers, such as `123` or `-456`. \n",
    "- **Float**: Numbers with decimals, like `3.14` or `-0.001`. \n",
    "- **Boolean**: True/False values, useful for binary decisions. \n",
    "- **Binary**: Data in binary format, something like `10101010`. \n",
    "- **Date**: Calendar dates in formats like `YYYY-MM-DD`. \n",
    "- **Timestamp**: Specific points in time like `2023-10-05 14:48:00`.\n",
    "- **Array**: Lists of elements, which can be strings, numbers, structs, or even other arrays.\n",
    "- **Struct**: Collections of key-value pairs. \n",
    "- **Object**: Objects with specified attributes. \n",
    "\n",
    "By generating structured outputs, LLMs can: \n",
    "- **integrate with systems**: Easily slot into existing databases, APIs, or other software. \n",
    "- **enable automation**: Power automated reporting, decision-making engines, and other workflows. \n",
    "- **enhance accuracy**: Ensure data consistency and integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dirtyjson as json\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, EmailStr, ValidationError\n",
    "from datetime import datetime\n",
    "from language_models.models.llm import OpenAILanguageModel, ChatMessage, ChatMessageRole\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital city of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a string\"\"\"\n",
    "\n",
    "prompt = \"What is the capital city of France?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integer output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be an integer\"\"\"\n",
    "\n",
    "prompt = \"How many continents are there on Earth?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = int(output)\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Float output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be an float\"\"\"\n",
    "\n",
    "prompt = \"What is the value of Pi up to two decimal places?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.14\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = float(output)\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a boolean (true, false)\"\"\"\n",
    "\n",
    "prompt = \"Is the number 5 greater than 3?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "if output.lower() == \"true\":\n",
    "    print(True)\n",
    "elif output.lower() == \"false\":\n",
    "    print(False)\n",
    "else:\n",
    "    print(\"Could not parse output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a binary string\"\"\"\n",
    "\n",
    "prompt = \"What is the binary representation of the number 15?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1111\n"
     ]
    }
   ],
   "source": [
    "if bool(re.fullmatch(r\"[01]+\", output)):\n",
    "    print(output)\n",
    "else:\n",
    "    print(\"Could not parse output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract the date from the user's input text.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a date with the format: %Y-%m-%d\"\"\"\n",
    "\n",
    "prompt = \"We are excited to announce that our annual company retreat will be held on April 15, 2024. This event will be a great opportunity for team building and strategic planning.\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = datetime.strptime(output, \"%Y-%m-%d\")\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timestamp output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract the date from the user's input text.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a date with the format: %Y-%m-%d %H:%M:%S\"\"\"\n",
    "\n",
    "prompt = \"We are excited to announce that our annual company retreat will be held on April 15, 2024. This event will be a great opportunity for team building and strategic planning.\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-15 00:00:00\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = datetime.strptime(output, \"%Y-%m-%d %H:%M:%S\")\n",
    "    print(output)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Array output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract all numbers from the user's input text.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be an array of integers\"\"\"\n",
    "\n",
    "prompt = \"\"\"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C.\n",
    "\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = json.loads(output)\n",
    "    output = list(output)\n",
    "    if all(isinstance(entry, int) for entry in output):\n",
    "        print(output)\n",
    "    else:\n",
    "        raise ValueError(\"Could not parse output\")\n",
    "except Exception as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Struct output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schema_from_args(args: dict[str, Any]) -> dict[str, Any]:\n",
    "    schema = {}\n",
    "    for field, details in args.items():\n",
    "        field_type = details.get(\"type\")\n",
    "        items_type = details.get(\"items\", {}).get(\"type\")\n",
    "        format_type = details.get(\"items\", {}).get(\"format\") or details.get(\"format\")\n",
    "        if field_type == \"string\":\n",
    "            if format_type == \"date\":\n",
    "                schema[field] = \"<date>\"\n",
    "            elif format_type == \"date-time\":\n",
    "                schema[field] = \"<timestamp>\"\n",
    "            elif format_type == \"email\":\n",
    "                schema[field] = \"<email>\"\n",
    "            else:\n",
    "                schema[field] = \"<string>\"\n",
    "        elif field_type == \"integer\":\n",
    "            schema[field] = \"<integer>\"\n",
    "        elif field_type == \"number\":\n",
    "            schema[field] = \"<float>\"\n",
    "        elif field_type == \"boolean\":\n",
    "            schema[field] = \"<true or false>\"\n",
    "        elif field_type == \"array\":\n",
    "            if items_type == \"string\":\n",
    "                if format_type == \"date\":\n",
    "                    schema[field] = [\"<date>\"]\n",
    "                elif format_type == \"date-time\":\n",
    "                    schema[field] = [\"<timestamp>\"]\n",
    "                elif format_type == \"email\":\n",
    "                    schema[field] = [\"<email>\"]\n",
    "                else:\n",
    "                    schema[field] = [\"<string>\"]\n",
    "            elif items_type == \"integer\":\n",
    "                schema[field] = [\"<integer>\"]\n",
    "            elif items_type == \"number\":\n",
    "                schema[field] = [\"<float>\"]\n",
    "            else:\n",
    "                schema[field] = []\n",
    "        else:\n",
    "            schema[field] = None\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': ['<email>'], 'subject': '<string>', 'body': '<string>'}\n"
     ]
    }
   ],
   "source": [
    "class Email(BaseModel):\n",
    "    to: list[EmailStr]\n",
    "    subject: str\n",
    "    body: str\n",
    "\n",
    "args = Email.model_json_schema()[\"properties\"]\n",
    "output_schema = get_schema_from_args(args)\n",
    "print(output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': ['johndoe@example.com', 'janedoe@example.com', 'alice.smith@company.org'], 'subject': 'Weekend Hiking Trip Recap', 'body': \"Hello,\n",
      "\n",
      "I hope this email finds you well. I'm writing to provide a recap of our exciting hiking trip last weekend.\n",
      "\n",
      "Six of us embarked on a 15-kilometer hike early in the morning at 7 AM. By noon, we had already covered 10 kilometers of our journey. We reached the summit of Mount Elbert, standing tall at 4,401 meters, by 2 PM. The weather was quite pleasant with a temperature of 12°C.\n",
      "\n",
      "Later, we set up our camp 5 kilometers away from the summit by 6 PM. We were joined by 12 other fellow hikers, making the evening even more enjoyable.\n",
      "\n",
      "The next day, we packed up and returned home by 5 PM, bringing our adventurous weekend to a close.\n",
      "\n",
      "Looking forward to more such trips in the future!\n",
      "\n",
      "Best regards,\"}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Write an email.\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "<response to the prompt>\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query and must be a JSON format with the keyword arguments: {output_schema}\"\"\"\n",
    "\n",
    "prompt = \"\"\"Send the email to:\n",
    "1. johndoe@example.com\n",
    "2. janedoe@example.com\n",
    "3. alice.smith@company.org\n",
    "\n",
    "Here is what we did: Weekend Hiking Trip Recap\n",
    "\n",
    "Here is some context:\n",
    "Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C.\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': ['johndoe@example.com', 'janedoe@example.com', 'alice.smith@company.org'], 'subject': 'Weekend Hiking Trip Recap', 'body': \"Hello,\\n\\nI hope this email finds you well. I'm writing to provide a recap of our exciting hiking trip last weekend.\\n\\nSix of us embarked on a 15-kilometer hike early in the morning at 7 AM. By noon, we had already covered 10 kilometers of our journey. We reached the summit of Mount Elbert, standing tall at 4,401 meters, by 2 PM. The weather was quite pleasant with a temperature of 12°C.\\n\\nLater, we set up our camp 5 kilometers away from the summit by 6 PM. We were joined by 12 other fellow hikers, making the evening even more enjoyable.\\n\\nThe next day, we packed up and returned home by 5 PM, bringing our adventurous weekend to a close.\\n\\nLooking forward to more such trips in the future!\\n\\nBest regards,\"}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = json.loads(output)\n",
    "    output = Email.model_validate(output)\n",
    "    print(output.model_dump())\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object output type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: ['johndoe@example.com', 'janedoe@example.com', 'alice.smith@company.org']\n",
      "Subject: Weekend Hiking Trip Recap\n",
      "Body: Hello,\n",
      "\n",
      "I hope this email finds you well. I'm writing to provide a recap of our exciting hiking trip last weekend.\n",
      "\n",
      "Six of us embarked on a 15-kilometer hike early in the morning at 7 AM. By noon, we had already covered 10 kilometers of our journey. We reached the summit of Mount Elbert, standing tall at 4,401 meters, by 2 PM. The weather was quite pleasant with a temperature of 12°C.\n",
      "\n",
      "Later, we set up our camp 5 kilometers away from the summit by 6 PM. We were joined by 12 other fellow hikers, making the evening even more enjoyable.\n",
      "\n",
      "The next day, we packed up and returned home by 5 PM, bringing our adventurous weekend to a close.\n",
      "\n",
      "Looking forward to more such trips in the future!\n",
      "\n",
      "Best regards,\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    output = Email.model_validate(output)\n",
    "    print(f\"To: {output.to}\")\n",
    "    print(f\"Subject: {output.subject}\")\n",
    "    print(f\"Body: {output.body}\")\n",
    "except ValidationError as error:\n",
    "    print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
