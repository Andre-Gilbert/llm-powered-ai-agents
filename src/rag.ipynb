{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation\n",
    "\n",
    "Table of Contents\n",
    "1. Idea\n",
    "2. Naive Implementation\n",
    "3. Graph Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from language_models.proxy_client import BTPProxyClient\n",
    "from language_models.agents.react import ReActAgent\n",
    "from language_models.agents.chain import AgentChain\n",
    "from language_models.tools.tool import Tool\n",
    "from language_models.models.llm import OpenAILanguageModel\n",
    "from language_models.models.embedding import SentenceTransformerEmbeddingModel\n",
    "from language_models.retrievers import BasicRetriever, ContextualCompressionRetriever\n",
    "from language_models.retrievers.utils import split_documents\n",
    "from language_models.vector_stores import FAISSVectorStore, DistanceMetric\n",
    "from language_models.settings import settings\n",
    "from langchain_core.documents import Document\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from pathlib import Path\n",
    "from langchain_core.documents import Document\n",
    "from utils import load_docs_from_json, save_docs_to_json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = BTPProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./data/jobs\")\n",
    "filenames = [file.name for file in path.iterdir() if file.is_file()]\n",
    "\n",
    "documents = []\n",
    "for filename in filenames:\n",
    "    file_path = path / filename\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\", errors=\"replace\") as file:\n",
    "        content = file.read()\n",
    "        documents.append(Document(page_content=content, metadata={\"source\": file_path}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Take the following job and extract data about the job.\n",
    "\n",
    "Respond with the following extracted data:\n",
    "- job_title: The job title.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=128,\n",
    "    float=0.0,\n",
    ")\n",
    "\n",
    "class Job(BaseModel):\n",
    "    job_title: str = Field(description=\"The job title.\")\n",
    "\n",
    "job_data_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"Job description:\\n{job}\",\n",
    "    task_prompt_variables=[\"job\"],\n",
    "    tools=None,\n",
    "    output_format=Job,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_job_titles(documents: list[Document]) -> pd.DataFrame:\n",
    "    for document in documents:\n",
    "        response = job_data_agent.invoke({\"job\": document.page_content})\n",
    "        job_title = response.final_answer[\"job_title\"]\n",
    "        document.metadata[\"job_title\"] = job_title\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    documents = load_docs_from_json('./data/jobs.json')\n",
    "except:\n",
    "    documents = extract_job_titles(documents[:30])\n",
    "    save_docs_to_json(documents, './data/jobs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = split_documents(documents, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], chunk_size=1000, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=256,\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert in job postings. Respond with the most accurate information about the job.\"\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"The final answer.\")\n",
    "\n",
    "agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{question}\",\n",
    "    task_prompt_variables=[\"question\"],\n",
    "    output_format=Output,\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke({\"question\": \"What is the salary range of an airport engineer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"What is the salary range of an airport engineer.\n",
    "\n",
    "Use this context to answer the question:\n",
    "AIRPORT ENGINEER\n",
    "Class Code:       7256\n",
    "Open Date:  07-06-18\n",
    "(Exam Open to All, including Current City Employees)\n",
    "\n",
    "ANNUAL SALARY\n",
    "\n",
    "$105,005 to $153,509 and $111,854 to $163,532.\"\"\"\n",
    "\n",
    "response = agent.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformerEmbeddingModel(model=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"What is the salary range of an airport engineer.\"\n",
    "embedding1 = embedding_model.embed_query(query1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query2 = \"\"\"AIRPORT ENGINEER\n",
    "Class Code:       7256\n",
    "Open Date:  07-06-18\n",
    "(Exam Open to All, including Current City Employees)\n",
    "\n",
    "ANNUAL SALARY\n",
    "\n",
    "$105,005 to $153,509 and $111,854 to $163,532.\"\"\"\n",
    "\n",
    "embedding2 = embedding_model.embed_query(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = dot(embedding1, embedding2) / (norm(embedding1) * norm(embedding2))\n",
    "print(f\"Cosine similarity: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    vector_store = FAISSVectorStore.load_local(\"./data\", \"job_embeddings\")\n",
    "except:\n",
    "    vector_store = FAISSVectorStore.from_documents(\n",
    "        documents=documents,\n",
    "        embedding_model=embedding_model,\n",
    "        distance_metric=DistanceMetric.COSINE_SIMILARITY,\n",
    "    )\n",
    "    vector_store.save_local(\"./data\", \"job_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_name = \"Search\"\n",
    "tool_description = \"Use this tool to search job postings.\"\n",
    "\n",
    "class Search(BaseModel):\n",
    "    user_text: str = Field(description=\"The user question/prompt/text.\")\n",
    "    fetch_k: int = Field(5, description=\"The number of documents to return.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_retriever = BasicRetriever(\n",
    "    vector_store=vector_store,\n",
    "    score_threshold=0.0\n",
    ")\n",
    "\n",
    "basic_retriever_tool = Tool(\n",
    "    func=basic_retriever.get_relevant_documents,\n",
    "    name=tool_name,\n",
    "    description=tool_description,\n",
    "    args_schema=Search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert in job postings. Respond with the most accurate information about the job.\n",
    "\n",
    "Use the search tool to answer the user's question.\"\"\"\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"The final answer.\")\n",
    "\n",
    "basic_retriever_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{question}\",\n",
    "    task_prompt_variables=[\"question\"],\n",
    "    output_format=Output,\n",
    "    tools=[basic_retriever_tool],\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = basic_retriever_agent.invoke({\"question\": \"Give me the job description of an airport engineer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextual_compression_retriever = ContextualCompressionRetriever(\n",
    "    llm=llm,\n",
    "    vector_store=vector_store,\n",
    "    score_threshold=0.0\n",
    ")\n",
    "\n",
    "contextual_compression_retriever_tool = Tool(\n",
    "    func=contextual_compression_retriever.get_relevant_documents,\n",
    "    name=tool_name,\n",
    "    description=tool_description,\n",
    "    args_schema=Search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert in job postings. Respond with the most accurate information about the job.\n",
    "\n",
    "Use the search tool to answer the user's question.\"\"\"\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"The final answer.\")\n",
    "\n",
    "contextual_compression_retriever_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{question}\",\n",
    "    task_prompt_variables=[\"question\"],\n",
    "    output_format=Output,\n",
    "    tools=[contextual_compression_retriever_tool],\n",
    "    iterations=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = basic_retriever_agent.invoke({\"question\": \"Give me the job description of an airport engineer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(documents: list[Document]) -> pd.DataFrame:\n",
    "    data = []\n",
    "    for document in documents:\n",
    "        embedding = embedding_model.embed_query(document.page_content)\n",
    "        data.append({\n",
    "            \"job_title\": document.metadata.get(\"job_title\") or \"\",\n",
    "            \"text\": document.page_content,\n",
    "            \"embedding\": embedding,\n",
    "            \"source\": document.metadata.get(\"source\") or \"\",\n",
    "        })\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataset(documents)\n",
    "data = {\"jobs\": df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs() -> list[str]:\n",
    "    return data[\"jobs\"].job_title.unique().tolist()\n",
    "\n",
    "get_jobs_tool = Tool(\n",
    "    func=get_jobs,\n",
    "    name=\"Get Jobs\",\n",
    "    description=\"Use this tool to get all available jobs.\",\n",
    "    args_schema=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Respond with the job title.\n",
    "\n",
    "- job_title: The job title. Make sure the Job Title is in all caps.\"\"\"\n",
    "\n",
    "class Job(BaseModel):\n",
    "    job_title: str = Field(description=\"The job title.\")\n",
    "\n",
    "job_agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{question}\",\n",
    "    task_prompt_variables=[\"question\"],\n",
    "    output_format=Job,\n",
    "    tools=[get_jobs_tool],\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search(BaseModel):\n",
    "    user_text: str = Field(description=\"The user question/prompt/text.\")\n",
    "    fetch_k: int = Field(5, description=\"The number of documents to return.\")\n",
    "    job_title: str = Field(description=\"The job title to filter for. Must be all caps.\")\n",
    "\n",
    "    @field_validator('job_title')\n",
    "    def check_all_caps(cls, value):\n",
    "        if not value.isupper():\n",
    "            raise ValueError('must be all uppercase')\n",
    "        return value\n",
    "\n",
    "def search(user_text: str, fetch_k: int, job_title: str) -> str:\n",
    "\n",
    "    def calculate_cosine_similarity(user_text_embedding, embedding):\n",
    "        cosine_similarity = dot(user_text_embedding, embedding) / (norm(user_text_embedding) * norm(embedding))\n",
    "        return cosine_similarity\n",
    "\n",
    "    user_text_embedding = embedding_model.embed_query(user_text)\n",
    "    df = data[\"jobs\"]\n",
    "    df = df.loc[df[\"job_title\"] == job_title].copy()\n",
    "    df[\"cosine_similarity\"] = df.embedding.apply(lambda embedding: calculate_cosine_similarity(user_text_embedding, embedding))\n",
    "    df = df.sort_values(by=\"cosine_similarity\", ascending=False)\n",
    "    df = df.iloc[:fetch_k]\n",
    "    documents = \"\\n\\n\".join(df.text.tolist())\n",
    "    return f\"Context:\\n\\n{documents}\"\n",
    "\n",
    "\n",
    "search_tool = Tool(\n",
    "    func=search,\n",
    "    name=tool_name,\n",
    "    description=tool_description,\n",
    "    args_schema=Search,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an expert in job postings. Respond with the most accurate information about the job.\n",
    "\n",
    "Use the search tool to answer the user's question.\"\"\"\n",
    "\n",
    "class Output(BaseModel):\n",
    "    content: str = Field(description=\"The final answer.\")\n",
    "\n",
    "agent = ReActAgent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    task_prompt=\"{job_title}\",\n",
    "    task_prompt_variables=[\"job_title\"],\n",
    "    output_format=Output,\n",
    "    tools=[search_tool],\n",
    "    iterations=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = AgentChain(\n",
    "    chain=[job_agent, agent],\n",
    "    chain_variables=[\"question\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\": \"Give me the job description of an airport engineer.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response.final_answer[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
