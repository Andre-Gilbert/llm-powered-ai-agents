{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Chapter: Tools\n",
    "\n",
    "LLMs use various tools to achieve specific goals, streamline operations, and automate tasks. These tools include:\n",
    "\n",
    "1. **Data retrieval tools:** Extract information from systems or databases using APIs, SDKs, and real-time metrics.\n",
    "2. **Communication tools:** Facilitate data exchange with external stakeholders via emails, notifications, or alerts.\n",
    "3. **Data manipulation tools:** Update or modify data within systems, often requiring approval to manage operational impacts.\n",
    "\n",
    "Additional tools also exist to handle tasks LLMs struggle with, like performing calculations or accessing current date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import dirtyjson as json\n",
    "from datetime import datetime\n",
    "from typing import Any, Callable\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from language_models.models.llm import OpenAILanguageModel, ChatMessage, ChatMessageRole\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=250,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow LLMs to leverage tools effectively, a few steps are needed. First, we need to communicate to the LLM that it has access to specific tools by providing the tool's name, a description of when or why the tool should be used, and the input arguments required for its successful execution. \n",
    "\n",
    "For our series on LLM-powered AI Agents, we will use Pydantic to simplify this process. When an LLM provides the input arguments, we need to validate them, execute the tool if the inputs are correct, and return the tool's output to the LLM. If the inputs are incorrect, we need to inform the LLM of the mistake so it can correct and resubmit the input.\n",
    "\n",
    "Tools should be represented in a format such as: Tool Name: ..., Tool Description: ..., Tool Input: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    \"\"\"Class that implements a tool.\n",
    "\n",
    "    Attributes:\n",
    "        function: The function that will be invoked when calling this tool.\n",
    "        name: The name of the tool.\n",
    "        description: The description of when to use the tool or what the tool does.\n",
    "        args_schema: The Pydantic model that represents the input arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    function: Callable[[Any], Any]\n",
    "    name: str\n",
    "    description: str\n",
    "    args_schema: type[BaseModel] | None = None\n",
    "\n",
    "    @property\n",
    "    def args(self) -> dict[str, Any] | None:\n",
    "        \"\"\"Gets the tool model JSON schema.\"\"\"\n",
    "        if self.args_schema is None:\n",
    "            return\n",
    "        return self.args_schema.model_json_schema()[\"properties\"]\n",
    "\n",
    "    def parse_input(self, tool_input: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Converts tool input to pydantic model.\"\"\"\n",
    "        input_args = self.args_schema\n",
    "        if input_args is not None:\n",
    "            result = input_args.model_validate(tool_input)\n",
    "            return {key: getattr(result, key) for key, _ in result.model_dump().items() if key in tool_input}\n",
    "        return tool_input\n",
    "\n",
    "    def invoke(self, tool_input: dict[str, Any]) -> Any:\n",
    "        \"\"\"Invokes a tool given arguments provided by an LLM.\"\"\"\n",
    "        if self.args is None:\n",
    "            output = self.function()\n",
    "        else:\n",
    "            try:\n",
    "                parsed_input = self.parse_input(tool_input)\n",
    "                output = self.function(**parsed_input)\n",
    "            except ValidationError as error:\n",
    "                output = \"\\n\\n\".join(\n",
    "                    [\n",
    "                        f\"Could not run tool {self.name} with input: {tool_input}\",\n",
    "                        f\"Here is the Pydantic validation error:\\n{error}\",\n",
    "                        \"Your should correct your response\",\n",
    "                        f\"Your <input of the tool to use> must be a JSON format with the keyword arguments of: {self.args}\",\n",
    "                    ]\n",
    "                )\n",
    "        return output\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"- Tool Name: {self.name}, Tool Description: {self.description}, Tool Input: {self.args}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, two tools are defined to be used by an LLM: \n",
    "- **a calculator tool**: The calculator tool uses an `eval` function to evaluate mathematical expressions provided as strings, with an accompanying Pydantic model to validate the input.\n",
    "- **a current date tool**: The current date tool provides the current local date and time. \n",
    "\n",
    "For each tool, a name, description, function, and, if needed, argument schema are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tool Name: Calculator, Tool Description: Use this tool when you want to do calculations, Tool Input: {'expression': {'description': 'A math expression', 'title': 'Expression', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "def calculator(expression: str) -> Any:\n",
    "    return eval(expression)\n",
    "\n",
    "class Calculator(BaseModel):\n",
    "    expression: str = Field(description=\"A math expression\")\n",
    "\n",
    "calculator_tool = Tool(\n",
    "    function=calculator,\n",
    "    name=\"Calculator\",\n",
    "    description=\"Use this tool when you want to do calculations\",\n",
    "    args_schema=Calculator,\n",
    ")\n",
    "\n",
    "print(calculator_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Tool Name: Current Date, Tool Description: Use this tool to access the current local date and time, Tool Input: None\n"
     ]
    }
   ],
   "source": [
    "def current_date() -> datetime:\n",
    "    return datetime.now()\n",
    "\n",
    "current_date_tool = Tool(\n",
    "    function=current_date,\n",
    "    name=\"Current Date\",\n",
    "    description=\"Use this tool to access the current local date and time\",\n",
    ")\n",
    "\n",
    "print(current_date_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setup, the `system_prompt` outlines how the LLM should structure its responses when addressing a user query. This includes specifying how and when to use the defined tools to solve the problems presented by users. The protocol involves a logical and ordered sequence of steps that the LLM should follow to produce a coherent and precise answer.\n",
    "\n",
    "When the LLM encounters a user prompt that requires a calculation or a specific operation, it must adhere to a predefined structure in its response:\n",
    "\n",
    "1. **Thought**: The LLM first generates a thought, which is an explanation or reasoning about what steps need to be taken to solve the problem.\n",
    "2. **Tool**: Based on the thought, the LLM selects the appropriate tool that is designed to perform the necessary operation.\n",
    "3. **Tool Input**: After selecting the tool, the LLM decides on the correct input needed for the tool to successfully complete the task or subtask.\n",
    "\n",
    "The order of thought, tool, and tool input is crucial. This is because LLMs work by predicting the next token with the highest probability based on the context provided by previous tokens. If the context is well-defined (i.e., the thought is clearly articulated), the LLM can more accurately choose the appropriate tool. Subsequently, given the tool and the thought, the LLM can then determine the precise input required for the tool to function correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to calculate the total cost of several items. I can use the Calculator tool to add up these costs.\n",
      "\n",
      "Tool: Calculator\n",
      "\n",
      "Tool Input: {\"expression\": \"549.72 + 6.98 + 41.00 + 35.00 + 552.00 + 76.16 + 29.12\"}\n"
     ]
    }
   ],
   "source": [
    "tools = [calculator_tool, current_date_tool]\n",
    "tools_str = \"\\n\\n\".join([str(tool) for tool in tools])\n",
    "\n",
    "system_prompt = f\"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Tools ###\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools_str}\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "Your <input of the tool to use> must be a JSON format with the keyword arguments of <name of the tool to use>\"\"\"\n",
    "\n",
    "tools_map = {tool.name: tool for tool in tools}\n",
    "\n",
    "prompt = \"Calculate the total raw cost = $549.72 + $6.98 + $41.00 + $35.00 + $552.00 + $76.16 + $29.12.\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt)\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `extract_tool_use(output: str)` is designed to parse a structured response from an LLM to extract three key components: the thought process, the name of the tool to be used, and the tool's input. It uses a regular expression pattern to match these components in the output string. If the pattern does not match, it raises a ValueError with guidance on the correct response format. When a match is found, it retrieves and trims the thought, tool, and tool input from the matched groups. This function ensures that the LLM's response adheres to the expected format and extracts necessary details for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_use(output: str) -> tuple[str, str, str]:\n",
    "    pattern = r\"\\s*Thought: (.*?)\\n+Tool: ([a-zA-Z0-9_ ]+).*?\\n+Tool Input: .*?(\\{.*\\})\"\n",
    "\n",
    "    match = re.search(pattern, output, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\n",
    "            f\"You made a mistake in your response: {output}\\n\\n\"\n",
    "            + f\"Your need to correct your response\\n\\n\"\n",
    "            + \"You should respond with:\\n```\\nThought: <thought process on how to respond to the prompt>\\n\\nTool: <name of the tool to use>\\n\\nTool Input: <input of the tool to use>\\n```\"\n",
    "        )\n",
    "\n",
    "    thought = match.group(1).strip()\n",
    "    tool = match.group(2).strip()\n",
    "    tool_input = match.group(3).strip()\n",
    "    return thought, tool, tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to calculate the total cost of several items. I can use the Calculator tool to add up these costs.\n",
      "Tool: Calculator\n",
      "Tool Input: {\"expression\": \"549.72 + 6.98 + 41.00 + 35.00 + 552.00 + 76.16 + 29.12\"}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    thought, tool, tool_input = extract_tool_use(output)\n",
    "    print(f\"Thought: {thought}\")\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(f\"Tool Input: {tool_input}\")\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1289.98\n"
     ]
    }
   ],
   "source": [
    "tool_input = json.loads(tool_input)\n",
    "tool = tools_map.get(tool)\n",
    "tool_output = tool.invoke(tool_input)\n",
    "print(tool_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, the `system_prompt` is an instruction set defining how an AI assistant should handle user queries, detailing step-by-step usage of available tools and structured response formats. It includes guidance on composing responses when using tools as well as when delivering the final answer. \n",
    "\n",
    "The `prompt` presented to the LLM is a request to calculate the total raw cost of a series of amounts, augmented by the LLM's previous work, including usage of the \"Calculator\" tool.\n",
    "\n",
    "Finally, the `llm.get_completion` function is invoked to generate a completion from the language model, following the provided instructions and prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to confirm the total raw cost of several items. The calculation was previously done and the total was found to be $1289.98. There is no need to recalculate as the previous calculation is correct.\n",
      "\n",
      "Final Answer: The total raw cost of the items is $1289.98.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Tools ###\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools_str}\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "Your <input of the tool to use> must be a JSON format with the keyword arguments of <name of the tool to use>\n",
    "\n",
    "When you know the final answer to the user's query you should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Final Answer: <response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query\"\"\"\n",
    "\n",
    "prompt = \"\"\"Calculate the total raw cost = $549.72 + $6.98 + $41.00 + $35.00 + $552.00 + $76.16 + $29.12.\n",
    "\n",
    "This was your previous work:\n",
    "\n",
    "Thought: The user wants to calculate the total cost of several items. I will use the Calculator tool to add up all the costs.\n",
    "\n",
    "Tool: Calculator\n",
    "\n",
    "Tool Input: {\"expression\": \"549.72 + 6.98 + 41.00 + 35.00 + 552.00 + 76.16 + 29.12\"}\n",
    "\n",
    "Observation: Tool Output: 1289.98\"\"\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `extract_final_answer(output: str)` is used to parse a structured response from an LLM to extract two key components: the thought process and the final answer. It utilizes a regular expression to identify and capture these components within the output string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_final_answer(output: str) -> tuple[str, str]:\n",
    "    pattern = r\"\\s*Thought: (.*?)\\n+Final Answer:([\\s\\S]*.*?)(?:$)\"\n",
    "\n",
    "    match = re.search(pattern, output, re.DOTALL)\n",
    "    if not match:\n",
    "        raise ValueError(\n",
    "            f\"You made a mistake in your response: {output}\\n\\n\"\n",
    "            + f\"Your need to correct your response\\n\\n\"\n",
    "            + \"You should respond with:\\n```\\nThought: <thought process on how to respond to the prompt>\\n\\nFinal Answer: <response to the prompt>\\n```\"\n",
    "        )\n",
    "\n",
    "    thought = match.group(1).strip()\n",
    "    final_answer = match.group(2).strip()\n",
    "    return thought, final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to confirm the total raw cost of several items. The calculation was previously done and the total was found to be $1289.98. There is no need to recalculate as the previous calculation is correct.\n",
      "Final Answer: The total raw cost of the items is $1289.98.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    thought, final_answer = extract_final_answer(output)\n",
    "    print(f\"Thought: {thought}\")\n",
    "    print(f\"Final Answer: {final_answer}\")\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's do the same thing to retrieve the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to know the current date. I can use the \"Current Date\" tool to provide this information.\n",
      "\n",
      "Tool: Current Date\n",
      "\n",
      "Tool Input: {}\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Tools ###\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools_str}\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "Your <input of the tool to use> must be a JSON format with the keyword arguments of <name of the tool to use>\n",
    "\n",
    "When you know the final answer to the user's query you should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Final Answer: <response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query\"\"\"\n",
    "\n",
    "prompt = \"What day do we have?\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The user wants to know the current date. I can use the \"Current Date\" tool to provide this information.\n",
      "Tool: Current Date\n",
      "Tool Input: {}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    thought, tool, tool_input = extract_tool_use(output)\n",
    "    print(f\"Thought: {thought}\")\n",
    "    print(f\"Tool: {tool}\")\n",
    "    print(f\"Tool Input: {tool_input}\")\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-04 19:47:05.379274\n"
     ]
    }
   ],
   "source": [
    "tool_input = json.loads(tool_input)\n",
    "tool = tools_map.get(tool)\n",
    "tool_output = tool.invoke(tool_input)\n",
    "print(tool_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The tool has provided the current date and time. The user only asked for the day, so I will extract that information from the output.\n",
      "\n",
      "Final Answer: Today is August 4, 2024.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = f\"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "### Tools ###\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools_str}\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "Your <input of the tool to use> must be a JSON format with the keyword arguments of <name of the tool to use>\n",
    "\n",
    "When you know the final answer to the user's query you should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Final Answer: <response to the prompt>\n",
    "```\n",
    "\n",
    "Your <response to the prompt> should be the final answer to the user's query\"\"\"\n",
    "\n",
    "prompt = \"\"\"What day do we have?\n",
    "\n",
    "This was your previous work:\n",
    "\n",
    "Thought: The user wants to know the current date. I can use the \"Current Date\" tool to provide this information.\n",
    "\n",
    "Tool: Current Date\n",
    "\n",
    "Tool Input: {}\n",
    "\n",
    "Observation: Tool Output: 2024-08-04 19:47:05.379274\"\"\"\n",
    "\n",
    "output = llm.get_completion([\n",
    "    ChatMessage(role=ChatMessageRole.SYSTEM, content=system_prompt),\n",
    "    ChatMessage(role=ChatMessageRole.USER, content=prompt),\n",
    "])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: The tool has provided the current date and time. The user only asked for the day, so I will extract that information from the output.\n",
      "Final Answer: Today is August 4, 2024.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    thought, final_answer = extract_final_answer(output)\n",
    "    print(f\"Thought: {thought}\")\n",
    "    print(f\"Final Answer: {final_answer}\")\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, it is clear that when an LLM doesn't have access to tools, we can use single completion prompts to obtain desired results. Conversely, if the LLM has tools, employing Chain-of-Thought prompting, particularly the ReAct prompting method, and requesting specific outputs that can be parsed using regular expressions becomes necessary. While outputs can be formatted in YAML or JSON for structured data representation, expressing outputs as plain text is more cost-effective."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
