{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 06: Multi-Agents\n",
    "\n",
    "In our discussions so far, we've dived into the world of AI agents and AI agent workflows, exploring how we can leverage LLMs to utilize various tools effectively. This foundational knowledge has set the stage for a natural progression: enabling LLMs to collaborate with other LLMs. By establishing a structured mechanism for these interactions, we can significantly enhance the capabilities and applications of our AI systems.  \n",
    "\n",
    "To facilitate this collaboration, we can utilize a familiar structure, which we have already employed for tool usage:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "By turning other LLMs into tools, we ensure that our workflow remains streamlined and efficient. This approach simplifies the decision-making process for the primary LLM, as it doesn't need to distinguish between calling a tool and calling another LLM - it simply calls a tool. The neat encapsulation of LLMs as tools allows us to maintain clarity and uniformity in the responses we seek from these interactions.  For our showcase, we will demonstrate this concept by transforming an existing workflow into a tool. As we have previously defined the inputs that a workflow expects, this transition will be smooth and illustrative of the powerful potential of multi-agent environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from assets.tools.earthquake import count_earthquakes, query_earthquakes, USGeopoliticalSurveyEarthquakeAPI\n",
    "from typing import Any\n",
    "from pydantic import BaseModel, Field\n",
    "from loguru import logger\n",
    "from language_models.agent import (\n",
    "    Agent,\n",
    "    OutputType,\n",
    "    PromptingStrategy,\n",
    "    WorkflowLLMStep,\n",
    "    WorkflowFunctionStep,\n",
    "    WorkflowTransformationStep,\n",
    "    WorkflowStateManager,\n",
    ")\n",
    "from language_models.tools import Tool, current_date\n",
    "from language_models.models.llm import OpenAILanguageModel\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.remove()\n",
    "logger.add(sys.stderr, format=\"{message}\", level=\"INFO\")\n",
    "\n",
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=500,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To integrate our workflow as a tool for use by an LLM, we simply add a new function that converts the workflow into an LLM-compatible tool, maintaining the defined inputs and utilizing the existing workflow execution structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkflowOutput(BaseModel):\n",
    "    \"\"\"Class that represents the workflow output.\"\"\"\n",
    "\n",
    "    inputs: dict[str, Any]\n",
    "    output: (\n",
    "        str\n",
    "        | int\n",
    "        | float\n",
    "        | dict[str, Any]\n",
    "        | BaseModel\n",
    "        | list[str]\n",
    "        | list[int]\n",
    "        | list[float]\n",
    "        | list[dict[str, Any]]\n",
    "        | list[BaseModel]\n",
    "        | None\n",
    "    )\n",
    "\n",
    "class Workflow(BaseModel):\n",
    "    \"\"\"Class that implements a workflow.\n",
    "\n",
    "    Attributes:\n",
    "        name: The name of the workflow.\n",
    "        description: The description of what the workflow does.\n",
    "        steps: The steps of the workflow.\n",
    "        inputs: The workflow inputs.\n",
    "        output: The name of the step value to output.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    description: str\n",
    "    steps: list[WorkflowLLMStep | WorkflowFunctionStep | WorkflowTransformationStep]\n",
    "    inputs: type[BaseModel]\n",
    "    output: str\n",
    "    verbose: bool\n",
    "\n",
    "    def invoke(self, inputs: dict[str, Any]) -> WorkflowOutput:\n",
    "        \"\"\"Runs the workflow.\"\"\"\n",
    "        _ = self.inputs.model_validate(inputs)\n",
    "        state_manager = WorkflowStateManager(state=inputs)\n",
    "        for step in self.steps:\n",
    "            output = step.invoke(state_manager.state, self.verbose)\n",
    "            state_manager.update(step.name, output)\n",
    "\n",
    "        output = state_manager.state.get(self.output)\n",
    "        if self.verbose:\n",
    "            logger.opt(colors=True).success(f\"<b><fg #32A467>Workflow Output</fg #32A467></b>: {output}\")\n",
    "\n",
    "        return WorkflowOutput(inputs=inputs, output=output)\n",
    "\n",
    "    def as_tool(self) -> Tool:\n",
    "        \"\"\"Converts the workflow into an LLM tool.\"\"\"\n",
    "        return Tool(\n",
    "            function=lambda **inputs: self.invoke(inputs).output,\n",
    "            name=self.name,\n",
    "            description=self.description,\n",
    "            args_schema=self.inputs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this setup, we first define individual workflows and tools that handle specific tasks, such as extracting numbers from text and querying earthquake data. By converting these workflows into tools, we can easily integrate them into an AI agent. Finally, we combine these agents into a chat agent that can leverage the capabilities of all the defined workflows and tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an AI assistant designed to help users with a variety of tasks.\n",
    "\n",
    "Extract all numbers from the user's input text.\"\"\"\n",
    "\n",
    "extractor_agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{prompt}\",\n",
    "    prompt_variables=[\"prompt\"],\n",
    "    output_type=OutputType.ARRAY_INTEGER,\n",
    "    prompting_strategy=PromptingStrategy.SINGLE_COMPLETION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_step = WorkflowLLMStep(name=\"numbers\", agent=extractor_agent)\n",
    "\n",
    "class Function(BaseModel):\n",
    "    numbers: list[int]\n",
    "\n",
    "function_step = WorkflowFunctionStep(name=\"sort\", inputs=Function, function=lambda numbers: sorted(numbers))\n",
    "\n",
    "filter_step = WorkflowTransformationStep(name=\"numbers_greater_10\", input_field=\"sort\", transformation=\"filter\", function=lambda number: number > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prompt(BaseModel):\n",
    "    prompt: str = Field(description=\"The user prompt\")\n",
    "\n",
    "extract_numbers_workflow = Workflow(\n",
    "    name=\"Find numbers greater than 10\",\n",
    "    description=\"Extracts numbers from a given text\",\n",
    "    steps=[agent_step, function_step, filter_step],\n",
    "    inputs=Prompt,\n",
    "    output=\"numbers_greater_10\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_earthquakes_tool = Tool(\n",
    "    function=query_earthquakes,\n",
    "    name=\"Query Earthquakes\",\n",
    "    description=\"Use this tool to search recent earthquakes\",\n",
    "    args_schema=USGeopoliticalSurveyEarthquakeAPI,\n",
    ")\n",
    "\n",
    "count_earthquakes_tool = Tool(\n",
    "    function=count_earthquakes,\n",
    "    name=\"Count Earthquakes\",\n",
    "    description=\"Use this tool to count and aggregate recent earthquakes\",\n",
    "    args_schema=USGeopoliticalSurveyEarthquakeAPI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an United States Geological Survey expert who can answer questions regarding earthquakes.\"\n",
    "\n",
    "earthquake_agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{question}\",\n",
    "    prompt_variables=[\"question\"],\n",
    "    output_type=OutputType.STRING,\n",
    "    tools=[current_date, count_earthquakes_tool, query_earthquakes_tool],\n",
    "    prompting_strategy=PromptingStrategy.CHAIN_OF_THOUGHT,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeQuery(BaseModel):\n",
    "    question: str = Field(description=\"The earthquake related user question\")\n",
    "\n",
    "earthquake_workflow = Workflow(\n",
    "    name=\"Earthquake Agent\",\n",
    "    description=\"Allows you to answer earthquake related questions\",\n",
    "    inputs=EarthquakeQuery,\n",
    "    output=\"earthquake\",\n",
    "    steps=[WorkflowLLMStep(name=\"earthquake\", agent=earthquake_agent)],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{prompt}\",\n",
    "    prompt_variables=[\"prompt\"],\n",
    "    tools=[extract_numbers_workflow.as_tool(), earthquake_workflow.as_tool()],\n",
    "    output_type=OutputType.STRING,\n",
    "    prompting_strategy=PromptingStrategy.CHAIN_OF_THOUGHT,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By invoking the agent with the prompt about today's earthquakes, we instruct it to use the earthquake agent encapsulated as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The user is asking about the number of earthquakes that occurred today. I can use the Earthquake Agent tool to get this information.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Earthquake Agent\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {'question': 'How many earthquakes happened today?'}\n",
      "\u001b[1m\u001b[38;2;45;114;210mUse LLM\u001b[0m\u001b[1m\u001b[0m: earthquake\n",
      "\u001b[1m\u001b[38;2;236;154;60mInputs\u001b[0m\u001b[1m\u001b[0m: {'question': 'How many earthquakes happened today?'}\n",
      "\u001b[1m\u001b[38;2;115;128;145mPrompt\u001b[0m\u001b[1m\u001b[0m: How many earthquakes happened today?\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: To answer this question, I need to count the number of earthquakes that occurred today. I can use the \"Count Earthquakes\" tool for this. I need to set the start_time to the beginning of today and the end_time to the current time.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Current Date\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {}\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: 2024-08-15 13:25:12.776357\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: Now that I have the current date and time, I can use it as the end_time in the \"Count Earthquakes\" tool. The start_time will be the beginning of today, which is at 00:00:00 hours of the current date.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Count Earthquakes\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {'start_time': '2024-08-15T00:00:00', 'end_time': '2024-08-15T13:25:12'}\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: {'count': 113, 'maxAllowed': 20000}\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The tool output provides the count of earthquakes that happened today. This is the information the user is asking for.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: There were 113 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;236;154;60mOutput\u001b[0m\u001b[1m\u001b[0m: There were 113 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;50;164;103mWorkflow Output\u001b[0m\u001b[1m\u001b[0m: There were 113 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: There were 113 earthquakes today.\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The tool has provided the number of earthquakes that occurred today. I can directly provide this information to the user.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: There were 113 earthquakes today.\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"prompt\": \"How many earthquakes happened today?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 113 earthquakes today.\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By invoking the agent with the prompt about a hiking trip, we instruct it to use the numbers extraction workflow encapsulated as a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The user wants to extract all numbers greater than 10 from the given text. I can use the \"Find numbers greater than 10\" tool to get this information.\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool\u001b[0m\u001b[1m\u001b[0m: Find numbers greater than 10\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Input\u001b[0m\u001b[1m\u001b[0m: {'prompt': \"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM. By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C. We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"}\n",
      "\u001b[1m\u001b[38;2;45;114;210mUse LLM\u001b[0m\u001b[1m\u001b[0m: numbers\n",
      "\u001b[1m\u001b[38;2;236;154;60mInputs\u001b[0m\u001b[1m\u001b[0m: {'prompt': \"Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM. By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C. We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"}\n",
      "\u001b[1m\u001b[38;2;115;128;145mPrompt\u001b[0m\u001b[1m\u001b[0m: Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM. By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C. We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "\u001b[1m\u001b[38;2;236;154;60mOutput\u001b[0m\u001b[1m\u001b[0m: [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]\n",
      "\u001b[1m\u001b[38;2;45;114;210mUse Function\u001b[0m\u001b[1m\u001b[0m: sort\n",
      "\u001b[1m\u001b[38;2;236;154;60mInputs\u001b[0m\u001b[1m\u001b[0m: {'numbers': [6, 15, 7, 10, 4401, 2, 12, 5, 6, 12, 5]}\n",
      "\u001b[1m\u001b[38;2;236;154;60mOutput\u001b[0m\u001b[1m\u001b[0m: [2, 5, 5, 6, 6, 7, 10, 12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;45;114;210mUse Transformation\u001b[0m\u001b[1m\u001b[0m: numbers_greater_10\n",
      "\u001b[1m\u001b[38;2;236;154;60mInputs\u001b[0m\u001b[1m\u001b[0m: {'sort': [2, 5, 5, 6, 6, 7, 10, 12, 12, 15, 4401]}\n",
      "\u001b[1m\u001b[38;2;236;154;60mOutput\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;50;164;103mWorkflow Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;236;154;60mTool Output\u001b[0m\u001b[1m\u001b[0m: [12, 12, 15, 4401]\n",
      "\u001b[1m\u001b[38;2;45;114;210mThought\u001b[0m\u001b[1m\u001b[0m: The tool has successfully extracted all numbers greater than 10 from the given text. These numbers are 12, 12, 15, and 4401.\n",
      "\u001b[1m\u001b[38;2;50;164;103mFinal Answer\u001b[0m\u001b[1m\u001b[0m: The numbers greater than 10 in the given context are 12, 12, 15, and 4401.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Extract all numbers > 10 from this context:\n",
    "\n",
    "Last weekend, six of us went on a 15-kilometer hike, starting at 7 AM.\n",
    "\n",
    "By noon, we had covered 10 kilometers and reached Mount Elbert's 4,401-meter summit by 2 PM, with a temperature of 12°C.\n",
    "\n",
    "We camped 5 kilometers away by 6 PM with 12 others and returned home by 5 PM the next day.\"\"\"\n",
    "\n",
    "output = agent.invoke({\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numbers greater than 10 in the given context are 12, 12, 15, and 4401.\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
