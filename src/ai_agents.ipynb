{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Chapter: AI Agents\n",
    "\n",
    "We've explored the incredible capabilities of LLMs, the art of prompting, the integration of tools, and the generation of structured outputs. With this strong foundation, we're now ready to dive into something even more powerful - creating our very own LLM-powered AI agent.  \n",
    "\n",
    "Here are just a few examples of what they can be used for: \n",
    "- **Customer support**: Provide instant, accurate, and empathetic responses to customer inquiries, improving satisfaction and efficiency. \n",
    "- **Content creation**: Generate high-quality articles, social media posts, and marketing copy with ease. \n",
    "- **Research assistance**: Summarize complex documents, find relevant studies, and provide insightful analysis. \n",
    "- **Personal assistants**: Manage schedules, set reminders, and help you stay organized. \n",
    "- **Creative expression**: Write stories, poems, and even act as a brainstorming partner for new ideas. \n",
    "- **Data analysis**: Process and interpret large datasets to extract meaningful patterns and insights.  \n",
    "\n",
    "With the ability to configure your LLM-powered AI agent for different scenarios and outputs, you unlock an incredible tool that can adapt to various roles and industries. The potential applications are vast, limited only by your imagination and creativity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from enum import Enum\n",
    "from typing import Any\n",
    "\n",
    "import tiktoken\n",
    "import requests\n",
    "from pydantic import BaseModel, Field, ValidationError, create_model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from language_models.agent.output_parser import (\n",
    "    FINAL_ANSWER_INSTRUCTIONS,\n",
    "    AgentOutputParser,\n",
    "    LLMSingleCompletionFinalAnswer,\n",
    "    LLMChainOfThoughtFinalAnswer,\n",
    "    LLMToolUse,\n",
    "    OutputType,\n",
    "    get_schema_from_args,\n",
    ")\n",
    "from language_models.models.llm import ChatMessage, ChatMessageRole, OpenAILanguageModel\n",
    "from language_models.tools.tool import Tool\n",
    "from language_models.models.llm import ChatMessage\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(message)s\",\n",
    "    datefmt=\"%d/%m/%y %H:%M:%S\",\n",
    ")\n",
    "\n",
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=1000,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code cell, we define instructions for an AI agent to follow when responding to different types of prompts: single completion, chain-of-thought with tools, and chain-of-thought without tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SINGLE_COMPLETION_INSTRUCTIONS = \"\"\"### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "<response to the prompt>\n",
    "```\"\"\"\n",
    "\n",
    "CHAIN_OF_THOUGHT_INSTRUCTIONS_WITH_TOOLS = \"\"\"### Tools ###\n",
    "\n",
    "You have access to the following tools:\n",
    "{tools}\n",
    "\n",
    "### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Tool: <name of the tool to use>\n",
    "\n",
    "Tool Input: <input of the tool to use>\n",
    "```\n",
    "\n",
    "Your <input of the tool to use> must be a JSON format with the keyword arguments of <name of the tool to use>\n",
    "\n",
    "When you know the final answer to the user's query you should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Final Answer: <response to the prompt>\n",
    "```\"\"\"\n",
    "\n",
    "CHAIN_OF_THOUGHT_INSTRUCTIONS_WITHOUT_TOOLS = \"\"\"### Instructions ###\n",
    "\n",
    "Your goal is to solve the problem you will be provided with\n",
    "\n",
    "You should respond with:\n",
    "```\n",
    "Thought: <thought process on how to respond to the prompt>\n",
    "\n",
    "Final Answer: <response to the prompt>\n",
    "```\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a `Chat` class that manages the chat history and a list of intermediate steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat(BaseModel):\n",
    "    \"\"\"Class that implements the chat history.\n",
    "\n",
    "    Attributes:\n",
    "        messages: The conversation history.\n",
    "        steps: The intermediate steps.\n",
    "    \"\"\"\n",
    "\n",
    "    messages: list[ChatMessage]\n",
    "    steps: list[str] = []\n",
    "\n",
    "    def update(self, prompt: str) -> None:\n",
    "        \"\"\"Modifies the user prompt to include intermediate steps.\"\"\"\n",
    "        self.messages[-1].content = prompt + \"\\n\\nThis was your previous work:\" + \"\\n\\n\".join(self.steps)\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the chat.\"\"\"\n",
    "        self.messages = [self.messages[0]]\n",
    "        self.steps = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the number of tokens in a conversation history to ensure it stays within the predefined limits for different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TOKEN_LIMIT = {\n",
    "    \"gpt-4\": 8192,\n",
    "    \"gpt-4-32k\": 32768,\n",
    "    \"gpt-35-turbo\": 4096,\n",
    "    \"gpt-35-turbo-16k\": 16385,\n",
    "}\n",
    "\n",
    "def num_tokens_from_messages(messages: list[ChatMessage]) -> int:\n",
    "    \"\"\"Counts the number of tokens in the conversation history.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4\n",
    "        for key, value in message.model_dump().items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += -1\n",
    "    num_tokens += 2\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create an `Agent` class was implemented to encapsulate an LLM-powered AI agent, providing methods for managing conversation context, parsing outputs, and executing the agent logic. Finally, we introduced a `create` class method to instantiate an agent with various configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptingStrategy(str, Enum):\n",
    "    SINGLE_COMPLETION = \"single completion\"\n",
    "    CHAIN_OF_THOUGHT = \"chain-of-thought\"\n",
    "\n",
    "class AgentOutput(BaseModel):\n",
    "    \"\"\"Class that represents the agent output.\"\"\"\n",
    "\n",
    "    prompt: str\n",
    "    final_answer: (\n",
    "        str\n",
    "        | int\n",
    "        | float\n",
    "        | dict[str, Any]\n",
    "        | BaseModel\n",
    "        | list[str]\n",
    "        | list[int]\n",
    "        | list[float]\n",
    "        | list[dict[str, Any]]\n",
    "        | list[BaseModel]\n",
    "        | None\n",
    "    )\n",
    "\n",
    "class Agent(BaseModel):\n",
    "    \"\"\"Class that implements an LLM-powered AI agent.\n",
    "\n",
    "    Attributes:\n",
    "        llm: The OpenAI LLM to use (in practice any model you choose).\n",
    "        tools: The tools the LLM can use.\n",
    "        prompt: The task prompt the LLM should solve.\n",
    "        prompt_variables: The task prompt variables that are needed to run the agent.\n",
    "        output_parser: The parser that handles LLM responses.\n",
    "        chat: The chat history.\n",
    "        prompt_strategy: The prompting strategy to use\n",
    "            (single completion for input/output type of queries, chain-of-thought for multi-step queries that involve tools).\n",
    "        iterations: The number of steps the LLM can take to solve the user query.\n",
    "        verbose: Enable logging.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: OpenAILanguageModel\n",
    "    tools: dict[str, Tool] | None\n",
    "    prompt: str\n",
    "    prompt_variables: list[str]\n",
    "    output_parser: AgentOutputParser\n",
    "    chat: Chat\n",
    "    prompting_strategy: PromptingStrategy\n",
    "    iterations: int = 10\n",
    "    verbose: bool\n",
    "\n",
    "    def trim_conversation(self) -> None:\n",
    "        \"\"\"Trims the chat messages to fit the LLM context length.\"\"\"\n",
    "        num_tokens = num_tokens_from_messages(self.chat.messages)\n",
    "        while num_tokens + self.llm.max_tokens >= MODEL_TOKEN_LIMIT[self.llm.model]:\n",
    "            del self.chat.messages[1]\n",
    "            num_tokens = num_tokens_from_messages(self.chat.messages)\n",
    "\n",
    "    def parse_output(self, output: str) -> LLMToolUse | LLMSingleCompletionFinalAnswer | LLMChainOfThoughtFinalAnswer:\n",
    "        \"\"\"Parses the LLM output.\"\"\"\n",
    "        try:\n",
    "            output = self.output_parser.parse(output)\n",
    "            observation = None\n",
    "        except (ValueError, ValidationError) as error:\n",
    "            output = None\n",
    "            observation = error\n",
    "        return output, observation\n",
    "\n",
    "    def invoke(self, prompt: dict[str, Any]) -> AgentOutput:\n",
    "        \"\"\"Runs the agent given a prompt.\"\"\"\n",
    "        prompt = self.prompt.format(**{variable: prompt.get(variable) for variable in self.prompt_variables})\n",
    "        if self.verbose:\n",
    "            logging.info(\"Prompt: %s\", prompt)\n",
    "\n",
    "        self.chat.messages.append(ChatMessage(role=ChatMessageRole.USER, content=prompt))\n",
    "        self.chat.steps = []\n",
    "\n",
    "        iteration = 0\n",
    "        while iteration <= self.iterations:\n",
    "            self.trim_conversation()\n",
    "            output = self.llm.get_completion(self.chat.messages)\n",
    "            if self.verbose:\n",
    "                logging.info(\"Raw Output: %s\", output)\n",
    "\n",
    "            output, observation = self.parse_output(output)\n",
    "\n",
    "            if self.prompting_strategy == PromptingStrategy.CHAIN_OF_THOUGHT:\n",
    "                if output is not None:\n",
    "                    if self.verbose:\n",
    "                        logging.info(\"Thought: %s\", output.thought)\n",
    "\n",
    "                    self.chat.steps.append(f\"Thought: {output.thought}\")\n",
    "\n",
    "                    if isinstance(output, LLMChainOfThoughtFinalAnswer):\n",
    "                        if self.verbose:\n",
    "                            logging.info(\"Final Answer: %s\", output.final_answer)\n",
    "\n",
    "                        self.chat.messages.append(\n",
    "                            ChatMessage(role=ChatMessageRole.ASSISTANT, content=str(output.final_answer))\n",
    "                        )\n",
    "                        return AgentOutput(prompt=prompt, final_answer=output.final_answer)\n",
    "\n",
    "                    else:\n",
    "                        if self.tools is not None:\n",
    "                            if self.verbose:\n",
    "                                logging.info(\"Tool: %s\", output.tool)\n",
    "                                logging.info(\"Tool Input: %s\", output.tool_input)\n",
    "\n",
    "                            tool = self.tools.get(output.tool)\n",
    "                            if tool is not None:\n",
    "                                tool_output = tool.invoke(output.tool_input)\n",
    "                                observation = f\"Tool Output: {tool_output}\"\n",
    "                                if self.verbose:\n",
    "                                    logging.info(observation)\n",
    "\n",
    "                                self.chat.steps.append(f\"Tool: {tool.name}\")\n",
    "                                self.chat.steps.append(f\"Tool Input: {output.tool_input}\")\n",
    "\n",
    "                            else:\n",
    "                                tool_names = \", \".join(list(self.tools.keys()))\n",
    "                                observation = f\"{output.tool} tool doesn't exist. Try one of these tools: {tool_names}\"\n",
    "\n",
    "                self.chat.steps.append(f\"Observation: {observation}\")\n",
    "                self.chat.update(prompt)\n",
    "\n",
    "            else:\n",
    "                if isinstance(output, LLMSingleCompletionFinalAnswer):\n",
    "                    if self.verbose:\n",
    "                        logging.info(\"Final Answer: %s\", output.final_answer)\n",
    "\n",
    "                    self.chat.messages.append(\n",
    "                        ChatMessage(role=ChatMessageRole.ASSISTANT, content=str(output.final_answer))\n",
    "                    )\n",
    "                    return AgentOutput(prompt=prompt, final_answer=output.final_answer)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        if self.output_parser.output_type == OutputType.STRUCT:\n",
    "            final_answer = {key: None for key in self.output_parser.output_schema.model_json_schema()[\"properties\"]}\n",
    "        elif self.output_parser.output_type == OutputType.ARRAY_STRUCT:\n",
    "            final_answer = [{key: None for key in self.output_parser.output_schema.model_json_schema()[\"properties\"]}]\n",
    "        elif self.output_parser.output_type in (OutputType.OBJECT, OutputType.ARRAY_OBJECT):\n",
    "            fields = self.output_parser.output_schema.__annotations__\n",
    "            optional_fields = {field: (data_type | None, None) for field, data_type in fields.items()}\n",
    "            model = create_model(self.output_parser.output_schema.__name__, **optional_fields)\n",
    "            final_answer = model() if self.output_parser.output_type == OutputType.OBJECT else [model()]\n",
    "        else:\n",
    "            final_answer = None\n",
    "\n",
    "        if self.verbose:\n",
    "            logging.info(\"Final Answer: %s\", final_answer)\n",
    "\n",
    "        return AgentOutput(prompt=prompt, final_answer=final_answer)\n",
    "\n",
    "    @classmethod\n",
    "    def create(\n",
    "        cls,\n",
    "        llm: OpenAILanguageModel,\n",
    "        system_prompt: str,\n",
    "        prompt: str,\n",
    "        prompt_variables: list[str],\n",
    "        output_type: OutputType,\n",
    "        output_schema: type[BaseModel] | str | None = None,\n",
    "        tools: list[Tool] | None = None,\n",
    "        prompting_strategy: PromptingStrategy = PromptingStrategy.CHAIN_OF_THOUGHT,\n",
    "        verbose: bool = True,\n",
    "    ) -> Agent:\n",
    "        \"\"\"Creates an instance of the Agent.\"\"\"\n",
    "        if prompting_strategy == PromptingStrategy.CHAIN_OF_THOUGHT:\n",
    "            if tools is None:\n",
    "                instructions = CHAIN_OF_THOUGHT_INSTRUCTIONS_WITHOUT_TOOLS\n",
    "                tool_use = False\n",
    "                tools = None\n",
    "                iterations = 5\n",
    "            else:\n",
    "                instructions = CHAIN_OF_THOUGHT_INSTRUCTIONS_WITH_TOOLS.format(\n",
    "                    tools=\"\\n\\n\".join([str(tool) for tool in tools])\n",
    "                )\n",
    "                tool_use = True\n",
    "                tools = {tool.name: tool for tool in tools}\n",
    "                iterations = max(5, len(tools) * 2)\n",
    "        else:\n",
    "            instructions = SINGLE_COMPLETION_INSTRUCTIONS\n",
    "            tool_use = False\n",
    "            iterations = 1\n",
    "\n",
    "        if output_type in (OutputType.OBJECT, OutputType.ARRAY_OBJECT):\n",
    "            if output_schema is None:\n",
    "                raise ValueError(f\"When using {output_type} as the output type a schema must be provided.\")\n",
    "\n",
    "            args = output_schema.model_json_schema()[\"properties\"]\n",
    "            final_answer_instructions = FINAL_ANSWER_INSTRUCTIONS[output_type].format(\n",
    "                output_schema=get_schema_from_args(args)\n",
    "            )\n",
    "        elif output_type in (OutputType.DATE, OutputType.TIMESTAMP):\n",
    "            final_answer_instructions = FINAL_ANSWER_INSTRUCTIONS[output_type].format(output_schema=output_schema)\n",
    "        else:\n",
    "            final_answer_instructions = FINAL_ANSWER_INSTRUCTIONS[output_type]\n",
    "\n",
    "        chat = Chat(\n",
    "            messages=[\n",
    "                ChatMessage(\n",
    "                    role=ChatMessageRole.SYSTEM,\n",
    "                    content=\"\\n\\n\".join([system_prompt, instructions, final_answer_instructions]),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        output_parser = AgentOutputParser(\n",
    "            output_type=output_type,\n",
    "            output_schema=output_schema,\n",
    "            prompting_strategy=prompting_strategy,\n",
    "            tool_use=tool_use,\n",
    "        )\n",
    "\n",
    "        return Agent(\n",
    "            llm=llm,\n",
    "            tools=tools,\n",
    "            prompt=prompt,\n",
    "            prompt_variables=prompt_variables,\n",
    "            output_parser=output_parser,\n",
    "            chat=chat,\n",
    "            prompting_strategy=prompting_strategy,\n",
    "            iterations=iterations,\n",
    "            verbose=verbose,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Completion\n",
    "\n",
    "The following code creates an AI agent that can answer user questions based on the internal knowledge of the LLM. It's designed to provide precise and detailed responses by leveraging a single completion strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an AI assistant designed to help users with a variety of tasks.\"\n",
    "\n",
    "agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{question}\",\n",
    "    prompt_variables=[\"question\"],\n",
    "    output_type=OutputType.STRING,\n",
    "    prompting_strategy=PromptingStrategy.SINGLE_COMPLETION,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/24 12:54:52 INFO Prompt: Hi, can you help me understand the basics of quantum computing?\n",
      "07/08/24 12:55:08 INFO Raw Output: Sure, I'd be happy to explain the basics of quantum computing!\n",
      "\n",
      "Quantum computing is a type of computation that uses quantum bits, or qubits, instead of the binary bits used in classical computing. While a classical bit can be in one of two states (0 or 1), a qubit can be in a superposition of states, meaning it can be in state 0, state 1, or any combination of both.\n",
      "\n",
      "This property, along with others like entanglement (where the state of one qubit can be instantaneously connected with the state of another, no matter the distance), allows quantum computers to process a massive number of possibilities all at once. \n",
      "\n",
      "Quantum computers can potentially solve certain types of problems much more efficiently than classical computers. For example, they could be used for complex simulations in quantum physics, factoring large numbers, optimizing large systems, and more.\n",
      "\n",
      "However, quantum computing is still in its early stages. Qubits are delicate and easily disturbed, which makes building a practical, large-scale quantum computer a significant challenge. Despite these challenges, many tech companies and research institutions are investing heavily in quantum computing research.\n",
      "07/08/24 12:55:08 INFO Final Answer: Sure, I'd be happy to explain the basics of quantum computing!\n",
      "\n",
      "Quantum computing is a type of computation that uses quantum bits, or qubits, instead of the binary bits used in classical computing. While a classical bit can be in one of two states (0 or 1), a qubit can be in a superposition of states, meaning it can be in state 0, state 1, or any combination of both.\n",
      "\n",
      "This property, along with others like entanglement (where the state of one qubit can be instantaneously connected with the state of another, no matter the distance), allows quantum computers to process a massive number of possibilities all at once. \n",
      "\n",
      "Quantum computers can potentially solve certain types of problems much more efficiently than classical computers. For example, they could be used for complex simulations in quantum physics, factoring large numbers, optimizing large systems, and more.\n",
      "\n",
      "However, quantum computing is still in its early stages. Qubits are delicate and easily disturbed, which makes building a practical, large-scale quantum computer a significant challenge. Despite these challenges, many tech companies and research institutions are investing heavily in quantum computing research.\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"question\": \"Hi, can you help me understand the basics of quantum computing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, I'd be happy to explain the basics of quantum computing!\n",
      "\n",
      "Quantum computing is a type of computation that uses quantum bits, or qubits, instead of the binary bits used in classical computing. While a classical bit can be in one of two states (0 or 1), a qubit can be in a superposition of states, meaning it can be in state 0, state 1, or any combination of both.\n",
      "\n",
      "This property, along with others like entanglement (where the state of one qubit can be instantaneously connected with the state of another, no matter the distance), allows quantum computers to process a massive number of possibilities all at once. \n",
      "\n",
      "Quantum computers can potentially solve certain types of problems much more efficiently than classical computers. For example, they could be used for complex simulations in quantum physics, factoring large numbers, optimizing large systems, and more.\n",
      "\n",
      "However, quantum computing is still in its early stages. Qubits are delicate and easily disturbed, which makes building a practical, large-scale quantum computer a significant challenge. Despite these challenges, many tech companies and research institutions are investing heavily in quantum computing research.\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/24 12:55:08 INFO Prompt: Alex has three times as many apples as Ben. Together, they have 24 apples. How many apples does each person have?\n",
      "07/08/24 12:55:14 INFO Raw Output: Let's denote the number of apples Ben has as x. According to the problem, Alex has 3 times as many apples as Ben, so Alex has 3x apples. Together, they have 24 apples. So, we can set up the following equation:\n",
      "\n",
      "x (Ben's apples) + 3x (Alex's apples) = 24\n",
      "\n",
      "Solving this equation gives:\n",
      "\n",
      "4x = 24\n",
      "x = 24 / 4\n",
      "x = 6\n",
      "\n",
      "So, Ben has 6 apples and Alex, having three times as many, has 18 apples.\n",
      "07/08/24 12:55:14 INFO Final Answer: Let's denote the number of apples Ben has as x. According to the problem, Alex has 3 times as many apples as Ben, so Alex has 3x apples. Together, they have 24 apples. So, we can set up the following equation:\n",
      "\n",
      "x (Ben's apples) + 3x (Alex's apples) = 24\n",
      "\n",
      "Solving this equation gives:\n",
      "\n",
      "4x = 24\n",
      "x = 24 / 4\n",
      "x = 6\n",
      "\n",
      "So, Ben has 6 apples and Alex, having three times as many, has 18 apples.\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"question\": \"Alex has three times as many apples as Ben. Together, they have 24 apples. How many apples does each person have?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's denote the number of apples Ben has as x. According to the problem, Alex has 3 times as many apples as Ben, so Alex has 3x apples. Together, they have 24 apples. So, we can set up the following equation:\n",
      "\n",
      "x (Ben's apples) + 3x (Alex's apples) = 24\n",
      "\n",
      "Solving this equation gives:\n",
      "\n",
      "4x = 24\n",
      "x = 24 / 4\n",
      "x = 6\n",
      "\n",
      "So, Ben has 6 apples and Alex, having three times as many, has 18 apples.\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain-of-Thought\n",
    "\n",
    "The following code configures an LLM to specialize in answering earthquake-related questions by simulating the expertise of a United States Geological Survey (USGS) expert. It integrates various tools, including those for earthquake information and current date retrieval, to enhance its responses. Additionally, the LLM's output is formatted according to a specified schema, ensuring clarity and consistency in its responses. The structured output format of the final answer will become more useful later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_date() -> datetime:\n",
    "    return datetime.now()\n",
    "\n",
    "current_date_tool = Tool(\n",
    "    function=current_date,\n",
    "    name=\"Current Date\",\n",
    "    description=\"Use this tool to access the current local date and time\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class USGeopoliticalSurveyEarthquakeAPI(BaseModel):\n",
    "    \"\"\"Class that implements the API interface.\"\"\"\n",
    "\n",
    "    start_time: str = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Limit to events on or after the specified start time. NOTE: All times use ISO8601 Date/Time format.\"\n",
    "            + \" Unless a timezone is specified, UTC is assumed.\"\n",
    "        ),\n",
    "    )\n",
    "    end_time: str = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Limit to events on or before the specified end time. NOTE: All times use ISO8601 Date/Time format.\"\n",
    "            + \" Unless a timezone is specified, UTC is assumed.\"\n",
    "        ),\n",
    "    )\n",
    "    limit: int = Field(\n",
    "        20000,\n",
    "        description=(\n",
    "            \"Limit the results to the specified number of events. NOTE: The service limits queries to 20000,\"\n",
    "            + \" and any that exceed this limit will generate a HTTP response code 400 Bad Request.\"\n",
    "        ),\n",
    "    )\n",
    "    min_depth: int = Field(\n",
    "        -100,\n",
    "        description=\"Limit to events with depth more than the specified minimum.\",\n",
    "    )\n",
    "    max_depth: int = Field(\n",
    "        1000,\n",
    "        description=\"Limit to events with depth less than the specified maximum.\",\n",
    "    )\n",
    "    min_magnitude: int = Field(\n",
    "        None,\n",
    "        description=\"Limit to events with a magnitude larger than the specified minimum.\",\n",
    "    )\n",
    "    max_magnitude: int = Field(\n",
    "        None,\n",
    "        description=\"Limit to events with a magnitude smaller than the specified maximum.\",\n",
    "    )\n",
    "    alert_level: str = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Limit to events with a specific PAGER alert level.\"\n",
    "            + \" The allowed values are: alert_level=green Limit to events with PAGER\"\n",
    "            + ' alert level \"green\". alert_level=yellow Limit to events with PAGER alert level \"yellow\".'\n",
    "            + ' alert_level=orange Limit to events with PAGER alert level \"orange\".'\n",
    "            + ' alert_level=red Limit to events with PAGER alert level \"red\".'\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def get_earthquakes(\n",
    "    endpoint: str,\n",
    "    start_time: datetime = (datetime.now() - timedelta(days=30)).date(),\n",
    "    end_time: datetime = datetime.now().date(),\n",
    "    limit: int = 20000,\n",
    "    min_depth: int = -100,\n",
    "    max_depth: int = 1000,\n",
    "    min_magnitude: int | None = None,\n",
    "    max_magnitude: int | None = None,\n",
    "    alert_level: str | None = None,\n",
    ") -> Any:\n",
    "    params = {\n",
    "        \"format\": \"geojson\",\n",
    "        \"starttime\": start_time,\n",
    "        \"endtime\": end_time,\n",
    "        \"limit\": limit,\n",
    "        \"mindepth\": min_depth,\n",
    "        \"maxdepth\": max_depth,\n",
    "        \"minmagnitude\": min_magnitude,\n",
    "        \"maxmagnitude\": max_magnitude,\n",
    "        \"alertlevel\": alert_level,\n",
    "        \"eventtype\": \"earthquake\",\n",
    "    }\n",
    "    response = requests.get(\n",
    "        f\"https://earthquake.usgs.gov/fdsnws/event/1/{endpoint}\",\n",
    "        params=params,\n",
    "        timeout=None,\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "def query_earthquakes(\n",
    "    start_time: datetime = (datetime.now() - timedelta(days=30)).date(),\n",
    "    end_time: datetime = datetime.now().date(),\n",
    "    limit: int = 20000,\n",
    "    min_depth: int = -100,\n",
    "    max_depth: int = 1000,\n",
    "    min_magnitude: int | None = None,\n",
    "    max_magnitude: int | None = None,\n",
    "    alert_level: str | None = None,\n",
    ") -> Any:\n",
    "    return get_earthquakes(\n",
    "        endpoint=\"query\",\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        limit=limit,\n",
    "        min_depth=min_depth,\n",
    "        max_depth=max_depth,\n",
    "        min_magnitude=min_magnitude,\n",
    "        max_magnitude=max_magnitude,\n",
    "        alert_level=alert_level,\n",
    "    )\n",
    "\n",
    "def count_earthquakes(\n",
    "    start_time: datetime = (datetime.now() - timedelta(days=30)).date(),\n",
    "    end_time: datetime = datetime.now().date(),\n",
    "    limit: int = 20000,\n",
    "    min_depth: int = -100,\n",
    "    max_depth: int = 1000,\n",
    "    min_magnitude: int | None = None,\n",
    "    max_magnitude: int | None = None,\n",
    "    alert_level: str | None = None,\n",
    ") -> Any:\n",
    "    return get_earthquakes(\n",
    "        endpoint=\"count\",\n",
    "        start_time=start_time,\n",
    "        end_time=end_time,\n",
    "        limit=limit,\n",
    "        min_depth=min_depth,\n",
    "        max_depth=max_depth,\n",
    "        min_magnitude=min_magnitude,\n",
    "        max_magnitude=max_magnitude,\n",
    "        alert_level=alert_level,\n",
    "    )\n",
    "\n",
    "query_earthquakes_tool = Tool(\n",
    "    function=query_earthquakes,\n",
    "    name=\"Query Earthquakes\",\n",
    "    description=\"Use this tool to search recent earthquakes\",\n",
    "    args_schema=USGeopoliticalSurveyEarthquakeAPI,\n",
    ")\n",
    "\n",
    "count_earthquakes_tool = Tool(\n",
    "    function=count_earthquakes,\n",
    "    name=\"Count Earthquakes\",\n",
    "    description=\"Use this tool to count and aggregate recent earthquakes\",\n",
    "    args_schema=USGeopoliticalSurveyEarthquakeAPI,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an United States Geological Survey expert who can answer questions regarding earthquakes.\"\n",
    "\n",
    "agent = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{question}\",\n",
    "    prompt_variables=[\"question\"],\n",
    "    output_type=OutputType.STRING,\n",
    "    tools=[current_date_tool, count_earthquakes_tool, query_earthquakes_tool],\n",
    "    prompting_strategy=PromptingStrategy.CHAIN_OF_THOUGHT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following question demonstrates how the LLM processes a user's query about the number of earthquakes that occurred on the current day. Using the provided tools, the LLM first retrieves the current date and time. This initial step is crucial for identifying and counting the seismic activities for the day. This process shows the power of Chain-of-Thought, particularly the ReAct prompting method, which enables the AI to tackle multi-step problems. By breaking down the task into smaller, manageable steps - first obtaining the current date, then querying the relevant seismic data - the LLM can deliver correct answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/24 12:55:14 INFO Prompt: How many earthquakes occurred today?\n",
      "07/08/24 12:55:17 INFO Raw Output: Thought: To answer this question, I need to first get the current date and then use the Count Earthquakes tool to count the number of earthquakes that occurred today.\n",
      "\n",
      "Tool: Current Date\n",
      "\n",
      "Tool Input: {}\n",
      "07/08/24 12:55:17 INFO Thought: To answer this question, I need to first get the current date and then use the Count Earthquakes tool to count the number of earthquakes that occurred today.\n",
      "07/08/24 12:55:17 INFO Tool: Current Date\n",
      "07/08/24 12:55:17 INFO Tool Input: {}\n",
      "07/08/24 12:55:17 INFO Tool Output: 2024-08-07 12:55:17.723312\n",
      "07/08/24 12:55:20 INFO Raw Output: Thought: Now that I have the current date, I can use the Count Earthquakes tool to count the number of earthquakes that occurred today.\n",
      "\n",
      "Tool: Count Earthquakes\n",
      "\n",
      "Tool Input: {\"start_date\": \"2024-08-07\", \"end_date\": \"2024-08-07\"}\n",
      "07/08/24 12:55:20 INFO Thought: Now that I have the current date, I can use the Count Earthquakes tool to count the number of earthquakes that occurred today.\n",
      "07/08/24 12:55:20 INFO Tool: Count Earthquakes\n",
      "07/08/24 12:55:20 INFO Tool Input: {'start_date': '2024-08-07', 'end_date': '2024-08-07'}\n",
      "07/08/24 12:55:21 INFO Tool Output: {'count': 9827, 'maxAllowed': 20000}\n",
      "07/08/24 12:55:24 INFO Raw Output: Thought: The Count Earthquakes tool has provided the number of earthquakes that occurred today. I can now provide this information to the user.\n",
      "\n",
      "Final Answer: There were 9827 earthquakes that occurred today.\n",
      "07/08/24 12:55:24 INFO Thought: The Count Earthquakes tool has provided the number of earthquakes that occurred today. I can now provide this information to the user.\n",
      "07/08/24 12:55:24 INFO Final Answer: There were 9827 earthquakes that occurred today.\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"question\": \"How many earthquakes occurred today?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 9827 earthquakes that occurred today.\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we give the LLM a follow-up question where `Show me 3` refers to the earthquakes that occurred today. By keeping track of the chat history, the LLM can understand the context and continuity of the conversation. This enables the LLM to recognize that \"today\" is the time frame in question and to provide details about three specific earthquakes that occurred on the current day. This capability to maintain and utilize chat history is essential for multi-turn interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/24 12:55:24 INFO Prompt: Show me 3.\n",
      "07/08/24 12:55:27 INFO Raw Output: Thought: To show the details of 3 earthquakes that occurred today, I can use the Query Earthquakes tool. I will need to specify the start date, end date, and limit the results to 3.\n",
      "\n",
      "Tool: Query Earthquakes\n",
      "\n",
      "Tool Input: {\"start_date\": \"2024-08-07\", \"end_date\": \"2024-08-07\", \"limit\": 3}\n",
      "07/08/24 12:55:27 INFO Thought: To show the details of 3 earthquakes that occurred today, I can use the Query Earthquakes tool. I will need to specify the start date, end date, and limit the results to 3.\n",
      "07/08/24 12:55:27 INFO Tool: Query Earthquakes\n",
      "07/08/24 12:55:27 INFO Tool Input: {'start_date': '2024-08-07', 'end_date': '2024-08-07', 'limit': 3}\n",
      "07/08/24 12:55:27 INFO Tool Output: {'type': 'FeatureCollection', 'metadata': {'generated': 1723028127000, 'url': 'https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2024-07-08&endtime=2024-08-07&limit=3&mindepth=-100&maxdepth=1000&eventtype=earthquake', 'title': 'USGS Earthquakes', 'status': 200, 'api': '1.14.1', 'limit': 3, 'offset': 1, 'count': 3}, 'features': [{'type': 'Feature', 'properties': {'mag': 1.4, 'place': '134 km SE of McCarthy, Alaska', 'time': 1722987040908, 'updated': 1722987165799, 'tz': None, 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/ak024a2kkhp6', 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=ak024a2kkhp6&format=geojson', 'felt': None, 'cdi': None, 'mmi': None, 'alert': None, 'status': 'automatic', 'tsunami': 0, 'sig': 30, 'net': 'ak', 'code': '024a2kkhp6', 'ids': ',ak024a2kkhp6,', 'sources': ',ak,', 'types': ',origin,phase-data,', 'nst': None, 'dmin': None, 'rms': 0.78, 'gap': None, 'magType': 'ml', 'type': 'earthquake', 'title': 'M 1.4 - 134 km SE of McCarthy, Alaska'}, 'geometry': {'type': 'Point', 'coordinates': [-141.258, 60.5374, 16]}, 'id': 'ak024a2kkhp6'}, {'type': 'Feature', 'properties': {'mag': 1.46, 'place': '4 km NW of Boron, CA', 'time': 1722987002280, 'updated': 1722987436754, 'tz': None, 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/ci40864992', 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=ci40864992&format=geojson', 'felt': None, 'cdi': None, 'mmi': None, 'alert': None, 'status': 'automatic', 'tsunami': 0, 'sig': 33, 'net': 'ci', 'code': '40864992', 'ids': ',ci40864992,', 'sources': ',ci,', 'types': ',nearby-cities,origin,phase-data,scitech-link,', 'nst': 38, 'dmin': 0.09605, 'rms': 0.2, 'gap': 51, 'magType': 'ml', 'type': 'earthquake', 'title': 'M 1.5 - 4 km NW of Boron, CA'}, 'geometry': {'type': 'Point', 'coordinates': [-117.6781667, 35.0295, -0.71]}, 'id': 'ci40864992'}, {'type': 'Feature', 'properties': {'mag': 4, 'place': '2 km WNW of Grębocice, Poland', 'time': 1722986533561, 'updated': 1722987380040, 'tz': None, 'url': 'https://earthquake.usgs.gov/earthquakes/eventpage/us6000nifx', 'detail': 'https://earthquake.usgs.gov/fdsnws/event/1/query?eventid=us6000nifx&format=geojson', 'felt': None, 'cdi': None, 'mmi': None, 'alert': None, 'status': 'reviewed', 'tsunami': 0, 'sig': 246, 'net': 'us', 'code': '6000nifx', 'ids': ',us6000nifx,', 'sources': ',us,', 'types': ',origin,phase-data,', 'nst': 46, 'dmin': 1.262, 'rms': 0.93, 'gap': 39, 'magType': 'mb', 'type': 'earthquake', 'title': 'M 4.0 - 2 km WNW of Grębocice, Poland'}, 'geometry': {'type': 'Point', 'coordinates': [16.125, 51.6044, 4.999]}, 'id': 'us6000nifx'}], 'bbox': [-141.258, 35.0295, -0.71, 16.125, 60.5374, 16]}\n",
      "07/08/24 12:55:35 INFO Raw Output: Here are the details of 3 earthquakes that occurred today:\n",
      "\n",
      "1. A magnitude 1.4 earthquake occurred 134 km SE of McCarthy, Alaska. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ak024a2kkhp6).\n",
      "\n",
      "2. A magnitude 1.46 earthquake occurred 4 km NW of Boron, CA. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ci40864992).\n",
      "\n",
      "3. A magnitude 4 earthquake occurred 2 km WNW of Grębocice, Poland. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/us6000nifx).\n",
      "07/08/24 12:55:48 INFO Raw Output: Thought: The user wants to see details of 3 earthquakes that occurred today. I have already used the Query Earthquakes tool to get this information. I will now present this information in a user-friendly format.\n",
      "\n",
      "Final Answer: Here are the details of 3 earthquakes that occurred today:\n",
      "\n",
      "1. A magnitude 1.4 earthquake occurred 134 km SE of McCarthy, Alaska. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ak024a2kkhp6).\n",
      "\n",
      "2. A magnitude 1.46 earthquake occurred 4 km NW of Boron, CA. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ci40864992).\n",
      "\n",
      "3. A magnitude 4 earthquake occurred 2 km WNW of Grębocice, Poland. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/us6000nifx).\n",
      "07/08/24 12:55:48 INFO Thought: The user wants to see details of 3 earthquakes that occurred today. I have already used the Query Earthquakes tool to get this information. I will now present this information in a user-friendly format.\n",
      "07/08/24 12:55:48 INFO Final Answer: Here are the details of 3 earthquakes that occurred today:\n",
      "\n",
      "1. A magnitude 1.4 earthquake occurred 134 km SE of McCarthy, Alaska. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ak024a2kkhp6).\n",
      "\n",
      "2. A magnitude 1.46 earthquake occurred 4 km NW of Boron, CA. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ci40864992).\n",
      "\n",
      "3. A magnitude 4 earthquake occurred 2 km WNW of Grębocice, Poland. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/us6000nifx).\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"question\": \"Show me 3.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the details of 3 earthquakes that occurred today:\n",
      "\n",
      "1. A magnitude 1.4 earthquake occurred 134 km SE of McCarthy, Alaska. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ak024a2kkhp6).\n",
      "\n",
      "2. A magnitude 1.46 earthquake occurred 4 km NW of Boron, CA. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/ci40864992).\n",
      "\n",
      "3. A magnitude 4 earthquake occurred 2 km WNW of Grębocice, Poland. More details can be found [here](https://earthquake.usgs.gov/earthquakes/eventpage/us6000nifx).\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM can also handle straightforward informational questions that don't require the use of additional tools. In this case, the question about the possibility of MegaQuakes (magnitude 10 or larger) can be answered directly by the language model without invoking any external tools. This shows the LLM's ability to recognize when it can rely on its internal knowledge base to provide an accurate response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07/08/24 12:55:48 INFO Prompt: Can MegaQuakes really happen? Like a magnitude 10 or larger?\n",
      "07/08/24 12:55:58 INFO Raw Output: Thought: The magnitude of an earthquake is a measure of the energy released during an earthquake. Theoretically, there is no upper limit to the magnitude of an earthquake. However, in practical terms, the physical properties of the Earth's crust limit the maximum size of earthquakes.\n",
      "\n",
      "Final Answer: Theoretically, there is no upper limit to the magnitude of an earthquake. However, in practical terms, the physical properties of the Earth's crust limit the maximum size of earthquakes. The largest earthquake ever recorded was a magnitude 9.5 in Chile in 1960. A magnitude 10 earthquake would release 31.6 times more energy than the 1960 Chilean earthquake. The likelihood of an event of such magnitude is extremely low.\n",
      "07/08/24 12:55:58 INFO Thought: The magnitude of an earthquake is a measure of the energy released during an earthquake. Theoretically, there is no upper limit to the magnitude of an earthquake. However, in practical terms, the physical properties of the Earth's crust limit the maximum size of earthquakes.\n",
      "07/08/24 12:55:58 INFO Final Answer: Theoretically, there is no upper limit to the magnitude of an earthquake. However, in practical terms, the physical properties of the Earth's crust limit the maximum size of earthquakes. The largest earthquake ever recorded was a magnitude 9.5 in Chile in 1960. A magnitude 10 earthquake would release 31.6 times more energy than the 1960 Chilean earthquake. The likelihood of an event of such magnitude is extremely low.\n"
     ]
    }
   ],
   "source": [
    "output = agent.invoke({\"question\": \"Can MegaQuakes really happen? Like a magnitude 10 or larger?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theoretically, there is no upper limit to the magnitude of an earthquake. However, in practical terms, the physical properties of the Earth's crust limit the maximum size of earthquakes. The largest earthquake ever recorded was a magnitude 9.5 in Chile in 1960. A magnitude 10 earthquake would release 31.6 times more energy than the 1960 Chilean earthquake. The likelihood of an event of such magnitude is extremely low.\n"
     ]
    }
   ],
   "source": [
    "print(output.final_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
