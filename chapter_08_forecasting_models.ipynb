{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 08: LLMs integrating with Forecasting Models\n",
    "\n",
    "Integrating LLMs with forecasting tools is a powerful strategy for enhancing decision-making across various domains. LLMs excel at interpreting complex datasets and generating actionable insights. When combined with forecasting models, this synergy allows for automatic forecast interpretation and action recommendations. While applications such as demand forecasting and machine degradation predictions are common, our focus will be on earthquake forecasting. We will outline practical steps for integrating LLMs with forecasting models, demonstrating how this combination can transform abstract concepts into actionable and insightful implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assets.tools.earthquake import count_earthquakes, query_earthquakes, USGeopoliticalSurveyEarthquakeAPI\n",
    "from assets.tools.forecasting import forecast_earthquakes, get_regions\n",
    "from pydantic import BaseModel, Field\n",
    "from language_models.models.llm import OpenAILanguageModel\n",
    "from language_models.agent import Agent, Workflow, WorkflowAgentStep, WorkflowFunctionStep, OutputType, PromptingStrategy\n",
    "from language_models.tools import Tool\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case: Automating Earthquake Forecast Inquiries\n",
    "\n",
    "Integrating LLMs with forecasting tools offers a transformative approach to managing inquiries about earthquake forecasts. Currently, handling these inquiries involves significant manual effort, with responses being drafted and sent individually. By automating this process, we can streamline operations and enhance efficiency. To automate responses to earthquake forecast inquiries effectively, we will design a workflow that integrates various steps, starting from the receipt of an email and ending in the generation of an email response, ensuring accurate and timely replies.\n",
    "\n",
    "**Step 1: Extracting Relevant Information**\n",
    "\n",
    "To handle the unstructured data in the email body, we first leverage an LLM. The LLM is tasked with extracting key details such as the regions and the forecasting horizons. This step is crucial as it transforms the free-form text into structured data. The LLM's natural language processing capabilities allow it to identify and extract mentions of specific regions and forecasting horizons from the email body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_regions_tool = Tool(\n",
    "    function=get_regions,\n",
    "    name=\"Get Valid Regions\",\n",
    "    description=\"Use this tool to access the valid regions that can be used for forecasting\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"Use the Get Valid Regions tool to determine the regions the user is interested in.\n",
    "\n",
    "The email body you receive may contain abbreviations or misspellings.\n",
    "\n",
    "Make sure to respond with the spelling provided by the Get Valid Regions tool.\"\"\"\n",
    "\n",
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model='gpt-4',\n",
    "    max_tokens=250,\n",
    "    temperature=0.2,\n",
    ")\n",
    "\n",
    "class Forecast(BaseModel):\n",
    "    horizon: int = Field(description=\"The number of days to forecast for\")\n",
    "    regions: list[str] = Field(description=\"The regions to forecast for\")\n",
    "\n",
    "extract_regions = Agent.create(\n",
    "    llm=llm,\n",
    "    system_prompt=system_prompt,\n",
    "    prompt=\"{email_body}\",\n",
    "    prompt_variables=[\"email_body\"],\n",
    "    tools=[get_regions_tool],\n",
    "    output_type=OutputType.OBJECT,\n",
    "    output_schema=Forecast,\n",
    "    prompting_strategy=PromptingStrategy.SINGLE_COMPLETION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "extract_regions_step = WorkflowAgentStep(name=\"extract_regions\", agent=extract_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionForecast(BaseModel):\n",
    "    region: str\n",
    "    forecast: list[dict]\n",
    "\n",
    "def forecast_earthquakes_for_regions(horizon: int, regions: list[str]) -> list[RegionForecast]:\n",
    "    forecasts = []\n",
    "    for region in regions:\n",
    "        forecast = forecast_earthquakes(region, horizon)\n",
    "        forecasts.append(RegionForecast(region=region, forecast=forecast))\n",
    "    return forecasts\n",
    "\n",
    "forecast_earthquakes_step = WorkflowFunctionStep(name=\"forecast_earthquakes\", inputs=Forecast, function=forecast_earthquakes_for_regions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_magnitude': 5.1, 'average_depth': 10.75}\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "\n",
    "# Sample list of dictionaries with magnitude and depth\n",
    "data = [\n",
    "    {'magnitude': 5.1, 'depth': 10.2},\n",
    "    {'magnitude': 4.8, 'depth': 12.5},\n",
    "    {'magnitude': 5.5, 'depth': 9.0},\n",
    "    {'magnitude': 5.0, 'depth': 11.3}\n",
    "]\n",
    "\n",
    "def calculate_averages(data):\n",
    "    # Extract magnitudes and depths\n",
    "    magnitudes = list(map(lambda x: x['magnitude'], data))\n",
    "    depths = list(map(lambda x: x['depth'], data))\n",
    "\n",
    "    # Sum of magnitudes and depths\n",
    "    total_magnitude = reduce(lambda x, y: x + y, magnitudes)\n",
    "    total_depth = reduce(lambda x, y: x + y, depths)\n",
    "\n",
    "    # Number of entries\n",
    "    count = len(data)\n",
    "\n",
    "    # Calculate averages\n",
    "    average_magnitude = total_magnitude / count if count > 0 else 0\n",
    "    average_depth = total_depth / count if count > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'average_magnitude': average_magnitude,\n",
    "        'average_depth': average_depth\n",
    "    }\n",
    "\n",
    "# Calculate and print the average values\n",
    "averages = calculate_averages(data)\n",
    "print(averages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-powered-ai-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
