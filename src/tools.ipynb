{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools\n",
    "\n",
    "LLMs use various tools to achieve specific goals, streamline operations, and automate tasks. These tools include:\n",
    "\n",
    "1. **Data retrieval tools:** Extract information from systems or databases using APIs, SDKs, and real-time metrics.\n",
    "2. **Communication tools:** Facilitate data exchange with external stakeholders via emails, notifications, or alerts.\n",
    "3. **Data manipulation tools:** Update or modify data within systems, often requiring approval to manage operational impacts.\n",
    "\n",
    "Additional tools also exist to handle tasks LLMs struggle with, like performing calculations or accessing current date and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "from typing import Any, Callable\n",
    "from language_models.models.llm import OpenAILanguageModel, ChatMessage, ChatMessageRole\n",
    "from language_models.proxy_client import ProxyClient\n",
    "from language_models.settings import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_client = ProxyClient(\n",
    "    client_id=settings.CLIENT_ID,\n",
    "    client_secret=settings.CLIENT_SECRET,\n",
    "    auth_url=settings.AUTH_URL,\n",
    "    api_base=settings.API_BASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILanguageModel(\n",
    "    proxy_client=proxy_client,\n",
    "    model=\"gpt-4\",\n",
    "    max_tokens=256,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "\n",
    "    def args(self) -> dict[str, Any] | None:\n",
    "        pass\n",
    "\n",
    "    def parse_input(self, tool_input: dict[str, Any]) -> dict[str, Any]:\n",
    "        pass\n",
    "\n",
    "    def invoke(self, tool_input: dict[str, Any]) -> Any:\n",
    "        pass\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    args_schema: type[BaseModel] | None = None\n",
    "\n",
    "    def args(self) -> dict[str, Any] | None:\n",
    "        if self.args_schema is None:\n",
    "            return\n",
    "        return self.args_schema.model_json_schema()[\"properties\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    args_schema: type[BaseModel] | None = None\n",
    "\n",
    "    def args(self) -> dict[str, Any] | None:\n",
    "        if self.args_schema is None:\n",
    "            return\n",
    "        return self.args_schema.model_json_schema()[\"properties\"]\n",
    "\n",
    "    def parse_input(self, tool_input: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Converts tool input to pydantic model.\"\"\"\n",
    "        input_args = self.args_schema\n",
    "        if input_args is not None:\n",
    "            result = input_args.model_validate(tool_input)\n",
    "            return {key: getattr(result, key) for key, _ in result.model_dump().items() if key in tool_input}\n",
    "        return tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    function: Callable[[Any], Any]\n",
    "    args_schema: type[BaseModel] | None = None\n",
    "\n",
    "    def args(self) -> dict[str, Any] | None:\n",
    "        if self.args_schema is None:\n",
    "            return\n",
    "        return self.args_schema.model_json_schema()[\"properties\"]\n",
    "\n",
    "    def parse_input(self, tool_input: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Converts tool input to pydantic model.\"\"\"\n",
    "        input_args = self.args_schema\n",
    "        if input_args is not None:\n",
    "            result = input_args.model_validate(tool_input)\n",
    "            return {key: getattr(result, key) for key, _ in result.model_dump().items() if key in tool_input}\n",
    "        return tool_input\n",
    "\n",
    "    def invoke(self, tool_input: dict[str, Any]) -> Any:\n",
    "        \"\"\"Invokes a tool given arguments provided by an LLM.\"\"\"\n",
    "        try:\n",
    "            parsed_input = self._parse_input(tool_input)\n",
    "            observation = self.function(**parsed_input) if parsed_input else self.function()\n",
    "        except ValidationError:\n",
    "            observation = (\n",
    "                f\"Could not run tool {self.name} with input: {tool_input}\\n\\n\"\n",
    "                + \"Your goal is to correct your response\\n\\n\"\n",
    "                + \"Your <input of the tool to use> must be a JSON format with the \"\n",
    "                + f\"keyword arguments of: {self.args}\"\n",
    "            )\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tool(BaseModel):\n",
    "    function: Callable[[Any], Any]\n",
    "    name: str\n",
    "    description: str\n",
    "    args_schema: type[BaseModel] | None = None\n",
    "\n",
    "    def args(self) -> dict[str, Any] | None:\n",
    "        if self.args_schema is None:\n",
    "            return\n",
    "        return self.args_schema.model_json_schema()[\"properties\"]\n",
    "\n",
    "    def parse_input(self, tool_input: dict[str, Any]) -> dict[str, Any]:\n",
    "        \"\"\"Converts tool input to pydantic model.\"\"\"\n",
    "        input_args = self.args_schema\n",
    "        if input_args is not None:\n",
    "            result = input_args.model_validate(tool_input)\n",
    "            return {key: getattr(result, key) for key, _ in result.model_dump().items() if key in tool_input}\n",
    "        return tool_input\n",
    "\n",
    "    def invoke(self, tool_input: dict[str, Any]) -> Any:\n",
    "        \"\"\"Invokes a tool given arguments provided by an LLM.\"\"\"\n",
    "        try:\n",
    "            parsed_input = self._parse_input(tool_input)\n",
    "            observation = self.function(**parsed_input) if parsed_input else self.function()\n",
    "        except ValidationError:\n",
    "            observation = (\n",
    "                f\"Could not run tool {self.name} with input: {tool_input}\\n\\n\"\n",
    "                + \"Your goal is to correct your response\\n\\n\"\n",
    "                + \"Your <input of the tool to use> must be a JSON format with the \"\n",
    "                + f\"keyword arguments of: {self.args}\"\n",
    "            )\n",
    "        return observation\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return f\"- Tool Name: {self.name}, \" f\"Tool Description: {self.description}, \" f\"Tool Input: {self.args}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
